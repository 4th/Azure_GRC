{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa552d09",
   "metadata": {
    "tags": [
     "TITLE"
    ]
   },
   "source": [
    "# Assembled Notebook â€” SK Agents (Cost Monitoring)\n",
    "_Generated 2025-11-08T04:21:14.291568Z_\n",
    "\n",
    "Notebook synthesized from your **Cost Monitoring Topology** Mermaid. Diagram is not embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c7027",
   "metadata": {
    "tags": [
     "SETUP"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP]\n",
    "!pip install -U semantic-kernel\n",
    "!pip -q uninstall -y pydrive2\n",
    "!pip install -q httpx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ba752",
   "metadata": {
    "tags": [
     "SETUP-ENV"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP-ENV]\n",
    "import os, getpass\n",
    "os.environ.setdefault('AZURE_OPENAI_ENDPOINT',    'https://4th-openai-resource.openai.azure.com')\n",
    "os.environ.setdefault('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "os.environ.setdefault('AZURE_OPENAI_DEPLOYMENT',  'gpt-35-turbo')\n",
    "if not os.getenv('AZURE_OPENAI_API_KEY'):\n",
    "    try:\n",
    "        os.environ['AZURE_OPENAI_API_KEY'] = getpass.getpass('Enter AZURE_OPENAI_API_KEY (hidden): ').strip()\n",
    "    except Exception:\n",
    "        pass\n",
    "print('Azure OpenAI env ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6351f5",
   "metadata": {
    "tags": [
     "KERNEL"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [KERNEL]\n",
    "import os\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "kernel = Kernel()\n",
    "service = AzureChatCompletion(\n",
    "    service_id='azure',\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
    "    endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    ")\n",
    "kernel.add_service(service)\n",
    "print('Kernel ready (Azure OpenAI)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa12eb",
   "metadata": {
    "tags": [
     "TOOLS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [TOOLS]\n",
    "import time, uuid, json\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "POLICY_STORE: Dict[str, Dict[str, Any]] = {\n",
    "    'tenant:acme': {\n",
    "        'chat':    {'model': 'gpt-35-turbo', 'caps': {'aoai_tokens': 4000, 'rag_calls': 4, 'http_bytes': 200_000}, 'slo': {'p95_ms': 6000, 'usd_per_turn': 0.08}},\n",
    "        'search':  {'model': 'gpt-35-turbo', 'caps': {'aoai_tokens': 2500, 'rag_calls': 6, 'http_bytes': 300_000}, 'slo': {'p95_ms': 8000, 'usd_per_turn': 0.05}},\n",
    "        'default': {'model': 'gpt-35-turbo', 'caps': {'aoai_tokens': 3000, 'rag_calls': 3, 'http_bytes': 150_000}, 'slo': {'p95_ms': 7000, 'usd_per_turn': 0.06}},\n",
    "    }\n",
    "}\n",
    "\n",
    "METER_STATE: Dict[str, Dict[str, Any]] = {}\n",
    "PRICE = {'gpt-35-turbo': {'input': 0.001, 'output': 0.002}}\n",
    "\n",
    "def tool_policy_lookup(tenant: str, intent: str) -> Dict[str, Any]:\n",
    "    t = POLICY_STORE.get(tenant) or {}\n",
    "    conf = t.get(intent) or t.get('default') or {}\n",
    "    return {'tenant': tenant, 'intent': intent, 'policy': conf}\n",
    "\n",
    "def _estimate_tokens(text: str) -> int:\n",
    "    return max(1, int(len(str(text)) / 4))\n",
    "\n",
    "def tool_meter_record(trace_id: str, kind: str, **metrics) -> Dict[str, Any]:\n",
    "    st = METER_STATE.setdefault(trace_id, {'aoai_tokens': 0, 'rag_calls': 0, 'http_bytes': 0, 'events': []})\n",
    "    st['events'].append({'t': time.time(), 'kind': kind, **metrics})\n",
    "    st['aoai_tokens'] += int(metrics.get('tokens', 0))\n",
    "    st['rag_calls'] += int(metrics.get('rag_calls', 0))\n",
    "    st['http_bytes'] += int(metrics.get('http_bytes', 0))\n",
    "    price = PRICE.get(metrics.get('model') or 'gpt-35-turbo', PRICE['gpt-35-turbo'])\n",
    "    in_tok = int(metrics.get('input_tokens', 0)); out_tok = int(metrics.get('output_tokens', 0))\n",
    "    usd = (in_tok * price['input'] + out_tok * price['output']) / 1000.0\n",
    "    st['usd'] = st.get('usd', 0.0) + usd\n",
    "    return {'ok': True, 'state': st}\n",
    "\n",
    "def tool_cap_check(trace_id: str, caps: Dict[str, int]) -> Dict[str, Any]:\n",
    "    st = METER_STATE.get(trace_id, {})\n",
    "    viol = []\n",
    "    for k, lim in (caps or {}).items():\n",
    "        val = int(st.get(k, 0))\n",
    "        if val > int(lim):\n",
    "            viol.append({'key': k, 'value': val, 'limit': lim})\n",
    "    return {'ok': len(viol) == 0, 'violations': viol, 'snapshot': st}\n",
    "\n",
    "async def tool_aoai_infer(kernel, trace_id: str, prompt: str, model: Optional[str] = None) -> Dict[str, Any]:\n",
    "    model = model or os.getenv('AZURE_OPENAI_DEPLOYMENT', 'gpt-35-turbo')\n",
    "    in_tok = _estimate_tokens(prompt)\n",
    "    try:\n",
    "        result = await kernel.invoke_prompt(prompt, service_id='azure')\n",
    "        out_text = str(result)\n",
    "        out_tok = _estimate_tokens(out_text)\n",
    "    except Exception as e:\n",
    "        out_text = f\"[AOAI stub due to error: {e}]\"\n",
    "        out_tok = _estimate_tokens(out_text)\n",
    "    tool_meter_record(trace_id, 'aoai', model=model, input_tokens=in_tok, output_tokens=out_tok, tokens=in_tok+out_tok)\n",
    "    return {'text': out_text, 'input_tokens': in_tok, 'output_tokens': out_tok, 'model': model}\n",
    "\n",
    "def tool_rag_search(trace_id: str, query: str, k: int = 3) -> Dict[str, Any]:\n",
    "    hits = [{'id': str(uuid.uuid4()), 'score': round(0.6 + 0.1*i, 3)} for i in range(k)]\n",
    "    tool_meter_record(trace_id, 'rag', rag_calls=1)\n",
    "    return {'hits': hits, 'k': k}\n",
    "\n",
    "def tool_http_request(trace_id: str, method: str, url: str, body: Optional[str] = None) -> Dict[str, Any]:\n",
    "    size = len(body or '') + len(url or '') + len(method or '')\n",
    "    tool_meter_record(trace_id, 'http', http_bytes=size)\n",
    "    return {'status': 200, 'bytes': size, 'url': url, 'method': method}\n",
    "\n",
    "def tool_soap_call(trace_id: str, wsdl: str, action: str, payload: Optional[str] = None) -> Dict[str, Any]:\n",
    "    size = len(payload or '') + len(wsdl or '') + len(action or '')\n",
    "    tool_meter_record(trace_id, 'soap', http_bytes=size)\n",
    "    return {'ok': True, 'action': action, 'bytes': size}\n",
    "\n",
    "TOOLS = {\n",
    "  'tool_policy_lookup': tool_policy_lookup,\n",
    "  'tool_meter_record': tool_meter_record,\n",
    "  'tool_cap_check': tool_cap_check,\n",
    "  'tool_aoai_infer': tool_aoai_infer,\n",
    "  'tool_rag_search': tool_rag_search,\n",
    "  'tool_http_request': tool_http_request,\n",
    "  'tool_soap_call': tool_soap_call,\n",
    "}\n",
    "print('Tools:', list(TOOLS.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e11dcd",
   "metadata": {
    "tags": [
     "AGENTS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [AGENTS]\n",
    "from typing import List\n",
    "\n",
    "class Agent_channel:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = 'Channel & Gateway'\n",
    "        self.system_message = 'You are the Channel & Gateway agent.'\n",
    "        self.skills = []\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            res = await self.kernel.invoke_prompt(self.system_message + '\\n\\nUser: ' + str(user_text), service_id='azure')\n",
    "            return str(res)\n",
    "        except Exception as ex:\n",
    "            return '[Channel & Gateway stub] ' + str(ex)\n",
    "\n",
    "class Agent_planner:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = 'Planner (intent, plan, toolset)'\n",
    "        self.system_message = 'Plan which tools to use and budgets to apply.'\n",
    "        self.skills = ['tool_policy_lookup']\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            res = await self.kernel.invoke_prompt(self.system_message + '\\n\\nUser: ' + str(user_text), service_id='azure')\n",
    "            return str(res)\n",
    "        except Exception as ex:\n",
    "            return '[Planner stub] ' + str(ex)\n",
    "    def call(self, tool_name: str, *args, **kwargs):\n",
    "        return TOOLS[tool_name](*args, **kwargs)\n",
    "\n",
    "class Agent_orchestrator:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = 'Orchestrator (SK / LangGraph)'\n",
    "        self.system_message = 'Execute plan within budget caps.'\n",
    "        self.skills = ['tool_aoai_infer','tool_rag_search','tool_http_request','tool_soap_call','tool_meter_record']\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            res = await self.kernel.invoke_prompt(self.system_message + '\\n\\nUser: ' + str(user_text), service_id='azure')\n",
    "            return str(res)\n",
    "        except Exception as ex:\n",
    "            return '[Orchestrator stub] ' + str(ex)\n",
    "    def call(self, tool_name: str, *args, **kwargs):\n",
    "        return TOOLS[tool_name](*args, **kwargs)\n",
    "\n",
    "class Agent_meter:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = 'Token Meter'\n",
    "        self.system_message = 'Track tokens, bytes, calls.'\n",
    "        self.skills = ['tool_meter_record','tool_cap_check']\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            res = await self.kernel.invoke_prompt(self.system_message + '\\n\\nUser: ' + str(user_text), service_id='azure')\n",
    "            return str(res)\n",
    "        except Exception as ex:\n",
    "            return '[Meter stub] ' + str(ex)\n",
    "    def call(self, tool_name: str, *args, **kwargs):\n",
    "        return TOOLS[tool_name](*args, **kwargs)\n",
    "\n",
    "class Agent_caps:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = 'Tool Budget Caps'\n",
    "        self.system_message = 'Enforce per-tool caps.'\n",
    "        self.skills = ['tool_cap_check']\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            res = await self.kernel.invoke_prompt(self.system_message + '\\n\\nUser: ' + str(user_text), service_id='azure')\n",
    "            return str(res)\n",
    "        except Exception as ex:\n",
    "            return '[Caps stub] ' + str(ex)\n",
    "    def call(self, tool_name: str, *args, **kwargs):\n",
    "        return TOOLS[tool_name](*args, **kwargs)\n",
    "\n",
    "agent_channel = Agent_channel(kernel)\n",
    "agent_planner = Agent_planner(kernel)\n",
    "agent_orchestrator = Agent_orchestrator(kernel)\n",
    "agent_meter = Agent_meter(kernel)\n",
    "agent_caps = Agent_caps(kernel)\n",
    "print('Agents:', ['agent_channel','agent_planner','agent_orchestrator','agent_meter','agent_caps'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b324c32",
   "metadata": {
    "tags": [
     "WIRES"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [WIRES]\n",
    "WIRES = {\n",
    "  'Channel & Gateway': [],\n",
    "  'Planner (intent, plan, toolset)': ['tool_policy_lookup'],\n",
    "  'Orchestrator (SK / LangGraph)': ['tool_aoai_infer','tool_rag_search','tool_http_request','tool_soap_call','tool_meter_record'],\n",
    "  'Token Meter': ['tool_meter_record','tool_cap_check'],\n",
    "  'Tool Budget Caps': ['tool_cap_check'],\n",
    "}\n",
    "print('Wiring entries:', len(WIRES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b2ddb",
   "metadata": {
    "tags": [
     "DEMO"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [DEMO]\n",
    "import asyncio, uuid\n",
    "\n",
    "async def demo_cost_turn(tenant='tenant:acme', intent='chat', query='Summarize budget caps in one sentence.'):\n",
    "    trace_id = str(uuid.uuid4())\n",
    "    print('trace_id:', trace_id)\n",
    "\n",
    "    pol = agent_planner.call('tool_policy_lookup', tenant=tenant, intent=intent)\n",
    "    policy = pol.get('policy', {})\n",
    "    caps = policy.get('caps', {})\n",
    "    model = policy.get('model')\n",
    "    print('policy:', policy)\n",
    "\n",
    "    rag = agent_orchestrator.call('tool_rag_search', trace_id=trace_id, query='cost meter patterns', k=2)\n",
    "    print('rag:', rag)\n",
    "\n",
    "    prompt = 'You are a concise assistant. ' + query\n",
    "    aoai = await TOOLS['tool_aoai_infer'](agent_orchestrator.kernel, trace_id=trace_id, prompt=prompt, model=model)\n",
    "    print('aoai tokens:', aoai.get('input_tokens'), '->', aoai.get('output_tokens'))\n",
    "\n",
    "    cap = agent_meter.call('tool_cap_check', trace_id=trace_id, caps=caps)\n",
    "    if not cap.get('ok'):\n",
    "        print('VIOLATIONS:', cap['violations'])\n",
    "    else:\n",
    "        print('Within caps \\u2713')\n",
    "\n",
    "    snap = METER_STATE.get(trace_id, {})\n",
    "    print('meter snapshot:', {k: v for k, v in snap.items() if k != 'events'})\n",
    "    return {'trace_id': trace_id, 'policy': policy, 'cap_ok': cap.get('ok'), 'meter': snap}\n",
    "\n",
    "await demo_cost_turn()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
