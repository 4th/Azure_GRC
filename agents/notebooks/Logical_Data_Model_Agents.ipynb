{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f861dcf8",
   "metadata": {
    "tags": [
     "TITLE"
    ]
   },
   "source": [
    "# Assembled Notebook â€” Logical Data Model Agents\n",
    "_Generated 2025-11-07T21:15:28.269936Z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22a75a",
   "metadata": {
    "tags": [
     "SETUP"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP]\n",
    "!pip install -U semantic-kernel\n",
    "!pip -q uninstall -y pydrive2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ff4a5",
   "metadata": {
    "tags": [
     "SETUP-ENV"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP-ENV]\n",
    "import os, getpass\n",
    "os.environ.setdefault('AZURE_OPENAI_ENDPOINT', 'https://4th-openai-resource.openai.azure.com')\n",
    "os.environ.setdefault('AZURE_OPENAI_DEPLOYMENT', 'gpt-35-turbo')\n",
    "os.environ.setdefault('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "if not os.getenv('AZURE_OPENAI_API_KEY'):\n",
    "    os.environ['AZURE_OPENAI_API_KEY'] = getpass.getpass('Enter AZURE_OPENAI_API_KEY (hidden): ').strip()\n",
    "print('Azure OpenAI env ready (key is session-only).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd691e0",
   "metadata": {
    "tags": [
     "KERNEL"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [KERNEL]\n",
    "import os\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service = AzureChatCompletion(\n",
    "    service_id='azure',\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
    "    endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    ")\n",
    "kernel.add_service(service)\n",
    "print('Kernel ready (Azure OpenAI)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae07a05",
   "metadata": {
    "tags": [
     "TOOLS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [TOOLS]\n",
    "\n",
    "def tool_schema_validate(**kwargs):\n",
    "    \"\"\"Validate records against the Logical Data Model.\"\"\"\n",
    "    return \"stub:schema_validate \" + str(kwargs)\n",
    "\n",
    "def tool_document_store(**kwargs):\n",
    "    \"\"\"Persist and retrieve Document records.\"\"\"\n",
    "    return \"stub:document_store \" + str(kwargs)\n",
    "\n",
    "def tool_chunker(**kwargs):\n",
    "    \"\"\"Produce ordered text chunks with section/page refs.\"\"\"\n",
    "    return \"stub:chunker \" + str(kwargs)\n",
    "\n",
    "def tool_embedding_store(**kwargs):\n",
    "    \"\"\"Persist Embedding vectors and metadata.\"\"\"\n",
    "    return \"stub:embedding_store \" + str(kwargs)\n",
    "\n",
    "def tool_embedder(**kwargs):\n",
    "    \"\"\"Generate embeddings for chunk text with a model.\"\"\"\n",
    "    return \"stub:embedder \" + str(kwargs)\n",
    "\n",
    "def tool_citation_store(**kwargs):\n",
    "    \"\"\"Persist Citation records.\"\"\"\n",
    "    return \"stub:citation_store \" + str(kwargs)\n",
    "\n",
    "def tool_toolcall_store(**kwargs):\n",
    "    \"\"\"Persist ToolCall entries.\"\"\"\n",
    "    return \"stub:toolcall_store \" + str(kwargs)\n",
    "\n",
    "def tool_trace_store(**kwargs):\n",
    "    \"\"\"Persist Trace envelopes and totals.\"\"\"\n",
    "    return \"stub:trace_store \" + str(kwargs)\n",
    "\n",
    "def tool_trace_log(**kwargs):\n",
    "    \"\"\"Append structured telemetry events (console stub).\"\"\"\n",
    "    return \"stub:trace_log \" + str(kwargs)\n",
    "\n",
    "\n",
    "TOOLS = {\n",
    "\n",
    "    'tool_schema_validate': tool_schema_validate,\n",
    "\n",
    "    'tool_document_store': tool_document_store,\n",
    "\n",
    "    'tool_chunker': tool_chunker,\n",
    "\n",
    "    'tool_embedding_store': tool_embedding_store,\n",
    "\n",
    "    'tool_embedder': tool_embedder,\n",
    "\n",
    "    'tool_citation_store': tool_citation_store,\n",
    "\n",
    "    'tool_toolcall_store': tool_toolcall_store,\n",
    "\n",
    "    'tool_trace_store': tool_trace_store,\n",
    "\n",
    "    'tool_trace_log': tool_trace_log,\n",
    "\n",
    "}\n",
    "print('Tools:', list(TOOLS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07cbed9",
   "metadata": {
    "tags": [
     "AGENTS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [AGENTS]\n",
    "\n",
    "class Agent_data_model_steward:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Data Model Steward\"\n",
    "        self.system_message = \"You are the Data Model Steward capability agent.\"\n",
    "        self.skills = [\"tool_schema_validate\", \"tool_trace_log\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Data Model Steward stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_ingestion_agent:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Ingestion Agent\"\n",
    "        self.system_message = \"You are the Ingestion Agent capability agent.\"\n",
    "        self.skills = [\"tool_document_store\", \"tool_trace_log\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Ingestion Agent stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_chunker_agent:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Chunker Agent\"\n",
    "        self.system_message = \"You are the Chunker Agent capability agent.\"\n",
    "        self.skills = [\"tool_chunker\", \"tool_document_store\", \"tool_trace_log\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Chunker Agent stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_embedder_agent:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Embedding Agent\"\n",
    "        self.system_message = \"You are the Embedding Agent capability agent.\"\n",
    "        self.skills = [\"tool_embedder\", \"tool_embedding_store\", \"tool_trace_log\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Embedding Agent stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_citation_agent:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Citation Agent\"\n",
    "        self.system_message = \"You are the Citation Agent capability agent.\"\n",
    "        self.skills = [\"tool_citation_store\", \"tool_trace_log\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Citation Agent stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_trace_orchestrator:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Trace Orchestrator\"\n",
    "        self.system_message = \"You are the Trace Orchestrator capability agent.\"\n",
    "        self.skills = [\"tool_toolcall_store\", \"tool_trace_store\", \"tool_trace_log\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Trace Orchestrator stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "\n",
    "# Instances\n",
    "\n",
    "agent_data_model_steward = Agent_data_model_steward(kernel)\n",
    "\n",
    "agent_ingestion_agent = Agent_ingestion_agent(kernel)\n",
    "\n",
    "agent_chunker_agent = Agent_chunker_agent(kernel)\n",
    "\n",
    "agent_embedder_agent = Agent_embedder_agent(kernel)\n",
    "\n",
    "agent_citation_agent = Agent_citation_agent(kernel)\n",
    "\n",
    "agent_trace_orchestrator = Agent_trace_orchestrator(kernel)\n",
    "\n",
    "print('Agents:', ['agent_data_model_steward', 'agent_ingestion_agent', 'agent_chunker_agent', 'agent_embedder_agent', 'agent_citation_agent', 'agent_trace_orchestrator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ccbb6e",
   "metadata": {
    "tags": [
     "WIRES"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [WIRES]\n",
    "WIRES = {\n",
    "  \"Data Model Steward\": {\n",
    "    \"tools\": [\n",
    "      \"tool_schema_validate\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Ingestion Agent\": {\n",
    "    \"tools\": [\n",
    "      \"tool_document_store\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Chunker Agent\": {\n",
    "    \"tools\": [\n",
    "      \"tool_chunker\",\n",
    "      \"tool_document_store\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Embedding Agent\": {\n",
    "    \"tools\": [\n",
    "      \"tool_embedder\",\n",
    "      \"tool_embedding_store\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Citation Agent\": {\n",
    "    \"tools\": [\n",
    "      \"tool_citation_store\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Trace Orchestrator\": {\n",
    "    \"tools\": [\n",
    "      \"tool_toolcall_store\",\n",
    "      \"tool_trace_store\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "print('Wiring entries:', len(WIRES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae35833",
   "metadata": {
    "tags": [
     "DEMO"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# %% [DEMO]\n",
    "import os, getpass, types, asyncio\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "os.environ.setdefault(\"AZURE_OPENAI_ENDPOINT\",    \"https://4th-openai-resource.openai.azure.com\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_DEPLOYMENT\",  \"gpt-35-turbo\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\")\n",
    "if not os.getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter AZURE_OPENAI_API_KEY (hidden): \").strip()\n",
    "\n",
    "try:\n",
    "    kernel\n",
    "except NameError:\n",
    "    kernel = Kernel()\n",
    "try:\n",
    "    kernel.remove_service(\"azure\")\n",
    "except Exception:\n",
    "    pass\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=\"azure\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "))\n",
    "\n",
    "async def _run_with_azure(self, user_text: str):\n",
    "    prompt = (getattr(self, \"system_message\", \"\") or \"\") + \"\\\\n\\\\nUser: \" + str(user_text)\n",
    "    result = await self.kernel.invoke_prompt(prompt, service_id=\"azure\")\n",
    "    return str(result)\n",
    "\n",
    "patched = []\n",
    "for name, obj in list(globals().items()):\n",
    "    if name.startswith(\"agent_\"):\n",
    "        try:\n",
    "            obj.kernel = kernel\n",
    "            obj.run = types.MethodType(_run_with_azure, obj)\n",
    "            patched.append(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "print(\"Patched run() for:\", patched if patched else \"(none)\")\n",
    "\n",
    "async def demo():\n",
    "    candidates = [v for k,v in globals().items() if k.startswith(\"agent_\") and \"tool_chunker\" in getattr(v, \"skills\", [])]\n",
    "    agent = candidates[0] if candidates else globals()[next((n for n in sorted(globals()) if n.startswith(\"agent_\")), None)]\n",
    "    print(\"Agent:\", getattr(agent, \"name\", \"(unknown)\"))\n",
    "    tools = agent.available_tools() if hasattr(agent, \"available_tools\") else []\n",
    "    print(\"Tools:\", tools)\n",
    "    if tools:\n",
    "        print(\"Tool demo:\", tools[0], \"->\", agent.call(tools[0], text=\"Hello world\", max_tokens=128))\n",
    "    print(\"LLM demo:\")\n",
    "    try:\n",
    "        out = await agent.run(\"Explain the relationship between Document, Chunk, and Embedding in one sentence.\")\n",
    "        print(out)\n",
    "    except Exception as e:\n",
    "        print(\"[demo] invoke failed:\", e)\n",
    "\n",
    "await demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
