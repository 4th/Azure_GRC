{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6a97f7",
   "metadata": {},
   "source": [
    "# PMBOK Governance — Agents Notebook\n",
    "\n",
    "Sections: **[SETUP] [SETUP-ENV] [KERNEL] [TOOLS] [AGENTS] [WIRES] [DEMO]**\n",
    "\n",
    "This notebook embeds your Mermaid diagram and sets up lightweight, stubbed agents/tools so you can dry-run orchestration without any external services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dd910",
   "metadata": {},
   "source": [
    "## Diagram\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "  %% ===================== PMBOK PROJECT GOVERNANCE CHECKPOINTS =====================\n",
    "  %% Phases aligned to PMBOK; gates & boards shown; steerco/PMO oversight\n",
    "\n",
    "  %% -------- GOVERNANCE ORG --------\n",
    "  subgraph GOV[\"Governance Bodies\"]\n",
    "    STEER[Steering Committee (SteerCo)]\n",
    "    PMO[PMO / Portfolio Board]\n",
    "    CCB[Change Control Board (CCB)]\n",
    "    QA[Quality/Audit]\n",
    "    FIN[Finance]\n",
    "  end\n",
    "\n",
    "  %% -------- INITIATING --------\n",
    "  subgraph INIT[\"Initiating\"]\n",
    "    G0{{Gate 0: Idea Intake\\n• Problem/Opportunity\\n• Sponsor Identified}}\n",
    "    CHARTER[Project Charter Approved\\n• Objectives, Scope, Success Criteria\\n• High-level Risks & Budget]\n",
    "    STAKE[Stakeholder Register\\n• RACI draft]\n",
    "  end\n",
    "\n",
    "  %% -------- PLANNING --------\n",
    "  subgraph PLAN[\"Planning\"]\n",
    "    G1{{Gate 1: Plan Approval\\n• Baseline Scope/Schedule/Cost\\n• Governance Plan}}\n",
    "    MGMTPLN[Integrated PM Plan\\n• Scope/WBS • Schedule • Cost • Quality\\n• Risk • Comms • Procurement • Resources]\n",
    "    GOVPLAN[Governance Plan\\n• Decision Rights • Escalation • Reporting Cadence]\n",
    "    RISKPLAN[Risk Register & Response Plan]\n",
    "    PROCU[Procurement Strategy / Make-Buy]\n",
    "  end\n",
    "\n",
    "  %% -------- EXECUTING --------\n",
    "  subgraph EXEC[\"Executing\"]\n",
    "    G2{{Gate 2: Readiness\\n• Team/Contracts Ready\\n• Risks & Controls in place}}\n",
    "    KICK[Kickoff + Comms Plan Live]\n",
    "    DELIV[Deliverables in Progress]\n",
    "    CHG[Change Requests → CCB]\n",
    "  end\n",
    "\n",
    "  %% -------- MONITOR & CONTROL --------\n",
    "  subgraph MON[\"Monitoring & Controlling\"]\n",
    "    PR[Periodic Reviews\\n• Status • Variance (SV/CV)\\n• Forecast (EAC/ETC)]\n",
    "    QG{{Quality Gate(s)\\n• Entry/Exit Criteria\\n• Test Evidence}}\n",
    "    RREV[Risk Reviews\\n• New/Residual Risk • Reserves]\n",
    "    FINREV[Financial Review\\n• Burn vs Budget • Benefits Outlook]\n",
    "    AUDIT[Audit/Assurance Checks]\n",
    "  end\n",
    "\n",
    "  %% -------- CLOSING --------\n",
    "  subgraph CLOSE[\"Closing\"]\n",
    "    G3{{Gate 3: Acceptance\\n• Scope Verified • UAT Sign-off}}\n",
    "    TRANS[Transition to Operations\\n• Support Model • SLAs]\n",
    "    LL[Lessons Learned • Retrospective]\n",
    "    BR[Benefits Realization Plan & Handover]\n",
    "    ARCH[Archive Artifacts • Contracts Closed]\n",
    "  end\n",
    "\n",
    "  %% ===================== FLOWS =====================\n",
    "  STEER --- PMO\n",
    "  PMO --- CCB\n",
    "  PMO --- QA\n",
    "  PMO --- FIN\n",
    "\n",
    "  G0 --> CHARTER --> STAKE --> G1\n",
    "  G1 --> MGMTPLN --> GOVPLAN --> RISKPLAN --> PROCU --> G2\n",
    "  G2 --> KICK --> DELIV --> PR\n",
    "  CHG --> CCB --> PR\n",
    "\n",
    "  PR --> QG --> PR\n",
    "  PR --> RREV --> PR\n",
    "  PR --> FINREV --> PR\n",
    "  QA --> AUDIT --> PR\n",
    "\n",
    "  PR -->|Meets tolerances| G3\n",
    "  PR -->|Breaches tolerances| STEER\n",
    "  STEER -->|Direction/Escalation| PR\n",
    "\n",
    "  G3 --> TRANS --> LL --> BR --> ARCH\n",
    "\n",
    "  %% ===================== NOTES =====================\n",
    "  %% - Gates (G0–G3) require documented criteria & sign-offs.\n",
    "  %% - Status reviews show EVM (SV/CV), forecast (EAC), risks, issues, decisions.\n",
    "  %% - CCB governs scope/time/cost changes; PMO tracks portfolio alignment.\n",
    "  %% - Quality gates enforce definition of done/ready; Audit samples compliance.\n",
    "  %% - Closing captures benefits handover and lessons for the portfolio.\n",
    "\n",
    "  %% ===================== STYLES =====================\n",
    "  classDef phase fill:#ecfeff,stroke:#06b6d4,stroke-width:2px,color:#134e4a;\n",
    "  classDef gate  fill:#fff7ed,stroke:#fb923c,stroke-width:2px,color:#7c2d12;\n",
    "  classDef gov   fill:#f5f3ff,stroke:#8b5cf6,stroke-width:2px,color:#4c1d95;\n",
    "\n",
    "  class GOV,STEER,PMO,CCB,QA,FIN gov\n",
    "  class INIT,PLAN,EXEC,MON,CLOSE phase\n",
    "  class G0,G1,G2,G3,QG gate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d94bde5",
   "metadata": {},
   "source": [
    "## %% [SETUP]\n",
    "Basic stdlib-only setup; no external installs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [SETUP]\n",
    "from __future__ import annotations\n",
    "import os, json, time, uuid, asyncio, random\n",
    "from dataclasses import dataclass, field\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e54dfd4",
   "metadata": {},
   "source": [
    "## %% [SETUP-ENV]\n",
    "Optional Azure OpenAI env (not required for this demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e09b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [SETUP-ENV]\n",
    "import os, getpass\n",
    "os.environ.setdefault('AZURE_OPENAI_ENDPOINT', 'https://example.openai.azure.com')\n",
    "os.environ.setdefault('AZURE_OPENAI_DEPLOYMENT', 'gpt-35-turbo')\n",
    "os.environ.setdefault('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "if not os.getenv('AZURE_OPENAI_API_KEY'):\n",
    "    try:\n",
    "        os.environ['AZURE_OPENAI_API_KEY'] = getpass.getpass('Enter AZURE_OPENAI_API_KEY (hidden, optional): ').strip()\n",
    "    except Exception:\n",
    "        pass\n",
    "print('Azure OpenAI env staged (key optional).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51efdcf",
   "metadata": {},
   "source": [
    "## %% [KERNEL]\n",
    "Minimal agent/kernel primitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc79c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [KERNEL]\n",
    "@dataclass\n",
    "class ToolResult:\n",
    "    name: str\n",
    "    ok: bool\n",
    "    data: dict\n",
    "\n",
    "class Tool:\n",
    "    def __init__(self, name, fn):\n",
    "        self.name = name\n",
    "        self._fn = fn\n",
    "    def invoke(self, **kwargs):\n",
    "        try:\n",
    "            return ToolResult(self.name, True, self._fn(**kwargs))\n",
    "        except Exception as e:\n",
    "            return ToolResult(self.name, False, {\"error\": str(e)})\n",
    "    def cost_estimate(self, **kwargs):\n",
    "        payload_size = sum(len(str(v)) for v in kwargs.values())\n",
    "        return max(1, payload_size // 20)\n",
    "\n",
    "class Planner:\n",
    "    def __init__(self, allow_tools=None):\n",
    "        self.allow_tools = set(allow_tools or [])\n",
    "    def plan(self, prompt: str, context: dict):\n",
    "        intent = context.get(\"intent\", \"general\")\n",
    "        steps = [\"precheck\", \"maybe_tool\", \"draft\", \"postcheck\"]\n",
    "        return {\"intent\": intent, \"steps\": steps, \"tool_budget\": 200}\n",
    "    def select_tools(self, intent: str):\n",
    "        return [t for t in self.allow_tools]\n",
    "\n",
    "class PolicyEngine:\n",
    "    def precheck(self, prompt: str, plan: dict):\n",
    "        return {\"allow\": True, \"constraints\": {\"max_tokens\": 400}}\n",
    "    def postcheck(self, answer: str, citations=None):\n",
    "        return {\"allow\": True, \"redact\": False}\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, name: str, tools: dict[str, Tool]):\n",
    "        self.name = name\n",
    "        self.id = str(uuid.uuid4())[:8]\n",
    "        self.tools = tools\n",
    "        self.planner = Planner(allow_tools=set(tools.keys()))\n",
    "        self.policy = PolicyEngine()\n",
    "    def available_tools(self):\n",
    "        return list(self.tools.keys())\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        t = self.tools.get(tool_name)\n",
    "        if not t:\n",
    "            return {\"error\": f\"tool '{tool_name}' not found\"}\n",
    "        res = t.invoke(**kwargs)\n",
    "        return res.data if res.ok else res.data\n",
    "    async def run(self, prompt: str, intent: str = \"general\"):\n",
    "        plan = self.planner.plan(prompt, {\"intent\": intent})\n",
    "        pre = self.policy.precheck(prompt, plan)\n",
    "        if not pre.get(\"allow\", True):\n",
    "            return {\"answer\": \"[refused by policy]\", \"citations\": [], \"confidence\": 0.0}\n",
    "        answer = f\"[{self.name}] Drafted response for intent='{intent}': {prompt[:160]}\"\n",
    "        post = self.policy.postcheck(answer, [])\n",
    "        conf = round(random.uniform(0.75, 0.98), 2)\n",
    "        return {\"answer\": answer, \"citations\": [], \"confidence\": conf}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f40bf",
   "metadata": {},
   "source": [
    "## %% [TOOLS]\n",
    "Stubbed tool adapters for governance use-cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec60e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [TOOLS]\n",
    "def t_policy_check(area:str, gate:str):\n",
    "    return {\"area\": area, \"gate\": gate, \"verdict\": \"pass\", \"notes\": \"Criteria met\"}\n",
    "def t_quality_gate(artifact:str, criteria:str):\n",
    "    return {\"artifact\": artifact, \"criteria\": criteria, \"evidence\": \"tests+docs\", \"verdict\": \"pass\"}\n",
    "def t_risk_review(phase:str):\n",
    "    return {\"phase\": phase, \"top_risks\": [\"scope creep\", \"vendor delay\"], \"status\": \"reviewed\"}\n",
    "def t_finance_review(period:str):\n",
    "    return {\"period\": period, \"burn_vs_budget\": \"within 3%\", \"forecast\": \"on-track\"}\n",
    "def t_audit_check(scope:str):\n",
    "    return {\"scope\": scope, \"sample_rate\": \"10%\", \"findings\": \"none\"}\n",
    "TOOLS = {\n",
    "    \"policy_check\": Tool(\"policy_check\", t_policy_check),\n",
    "    \"quality_gate\": Tool(\"quality_gate\", t_quality_gate),\n",
    "    \"risk_review\": Tool(\"risk_review\", t_risk_review),\n",
    "    \"finance_review\": Tool(\"finance_review\", t_finance_review),\n",
    "    \"audit_check\": Tool(\"audit_check\", t_audit_check),\n",
    "}\n",
    "print(\"Tools ready:\", \", \".join(TOOLS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93ef04",
   "metadata": {},
   "source": [
    "## %% [AGENTS]\n",
    "Agents aligned to PMBOK phases and governance bodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [AGENTS]\n",
    "agent_governance = Agent(\"SteerCo/PMO Agent\", {k: TOOLS[k] for k in (\"policy_check\",\"finance_review\",\"audit_check\")})\n",
    "agent_planning   = Agent(\"Planning Agent\",     {k: TOOLS[k] for k in (\"policy_check\",\"risk_review\",\"quality_gate\")})\n",
    "agent_execution  = Agent(\"Execution Agent\",    {k: TOOLS[k] for k in (\"quality_gate\",\"risk_review\")})\n",
    "agent_monitoring = Agent(\"Monitoring Agent\",   {k: TOOLS[k] for k in (\"risk_review\",\"finance_review\",\"audit_check\")})\n",
    "agent_closing    = Agent(\"Closing Agent\",      {k: TOOLS[k] for k in (\"quality_gate\",\"audit_check\")})\n",
    "agent_change     = Agent(\"Change Control Agent\",{k: TOOLS[k] for k in (\"policy_check\",\"quality_gate\")})\n",
    "\n",
    "AGENT_INDEX = {\n",
    "    \"governance\": agent_governance,\n",
    "    \"planning\": agent_planning,\n",
    "    \"execution\": agent_execution,\n",
    "    \"monitoring\": agent_monitoring,\n",
    "    \"closing\": agent_closing,\n",
    "    \"change\": agent_change,\n",
    "}\n",
    "print(\"Agents:\", \", \".join(f\"{k}:{v.name}\" for k,v in AGENT_INDEX.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722dcab5",
   "metadata": {},
   "source": [
    "## %% [WIRES]\n",
    "Route key checkpoints to agents + wiring counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29474ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [WIRES]\n",
    "ROUTES = {\n",
    "    \"Gate 0\": \"governance\",\n",
    "    \"Gate 1\": \"planning\",\n",
    "    \"Gate 2\": \"execution\",\n",
    "    \"Gate 3\": \"closing\",\n",
    "    \"Periodic Review\": \"monitoring\",\n",
    "    \"Change Request\": \"change\",\n",
    "}\n",
    "\n",
    "def validate_wiring():\n",
    "    problems = []\n",
    "    for checkpoint, key in ROUTES.items():\n",
    "        agent = AGENT_INDEX.get(key)\n",
    "        if not agent:\n",
    "            problems.append(f\"{checkpoint} -> missing agent key '{key}'\")\n",
    "            continue\n",
    "        if not agent.available_tools():\n",
    "            problems.append(f\"{checkpoint} -> {agent.name} has no available tools\")\n",
    "    return problems\n",
    "\n",
    "total_wires = len(ROUTES)\n",
    "distinct_agents = len(set(ROUTES.values()))\n",
    "unreferenced_agents = sorted(set(AGENT_INDEX.keys()) - set(ROUTES.values()))\n",
    "targets_by_agent = {}\n",
    "for cp, key in ROUTES.items():\n",
    "    targets_by_agent.setdefault(key, []).append(cp)\n",
    "\n",
    "issues = validate_wiring()\n",
    "print(f\"Wires: {total_wires} (distinct agents: {distinct_agents})\")\n",
    "for agent_key, cps in targets_by_agent.items():\n",
    "    agent_name = AGENT_INDEX[agent_key].name\n",
    "    print(f\"  - {agent_name} <- {len(cps)} checkpoint(s): {', '.join(cps)}\")\n",
    "if unreferenced_agents:\n",
    "    print(\"Unreferenced agents:\", \", \".join(unreferenced_agents))\n",
    "print(\"Wiring OK\" if not issues else \"Wiring issues:\\n- \" + \"\\n- \".join(issues))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1887605",
   "metadata": {},
   "source": [
    "## %% [DEMO]\n",
    "Notebook-safe async demo (no `asyncio.run()` loop issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ce8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [DEMO]\n",
    "# Simulated scenarios across checkpoints; tools are stubbed, LLM is a toy draft.\n",
    "import asyncio, time\n",
    "\n",
    "samples = [\n",
    "    (\"Gate 0\", \"Idea intake: AI chatbot for HR FAQs.\"),\n",
    "    (\"Gate 1\", \"Approve baseline plan and governance.\"),\n",
    "    (\"Gate 2\", \"Readiness check before kickoff.\"),\n",
    "    (\"Periodic Review\", \"Show SV/CV with EAC forecast.\"),\n",
    "    (\"Change Request\", \"Add scope for multilingual support.\"),\n",
    "    (\"Gate 3\", \"Acceptance and UAT sign-off.\"),\n",
    "]\n",
    "\n",
    "async def demo_run():\n",
    "    t0 = time.time()\n",
    "    outputs = []\n",
    "    for checkpoint, text in samples:\n",
    "        key = ROUTES[checkpoint]\n",
    "        agent = AGENT_INDEX[key]\n",
    "        tool_result = None\n",
    "        if key == \"planning\":\n",
    "            tool_result = agent.call(\"risk_review\", phase=\"planning\")\n",
    "        elif key == \"execution\":\n",
    "            tool_result = agent.call(\"quality_gate\", artifact=\"build#123\", criteria=\"DoR/DoD\")\n",
    "        elif key == \"monitoring\":\n",
    "            tool_result = agent.call(\"finance_review\", period=\"Q1\")\n",
    "        elif key == \"change\":\n",
    "            tool_result = agent.call(\"policy_check\", area=\"scope\", gate=\"CCB\")\n",
    "        elif key == \"closing\":\n",
    "            tool_result = agent.call(\"audit_check\", scope=\"UAT evidence\")\n",
    "        else:\n",
    "            tool_result = agent.call(\"policy_check\", area=\"governance\", gate=checkpoint)\n",
    "\n",
    "        llm_out = await agent.run(text, intent=key)\n",
    "        outputs.append({\n",
    "            \"checkpoint\": checkpoint,\n",
    "            \"agent\": agent.name,\n",
    "            \"tool_result\": tool_result,\n",
    "            \"llm_result\": llm_out[\"answer\"][:220] + (\"...\" if len(llm_out[\"answer\"])>220 else \"\"),\n",
    "            \"confidence\": llm_out[\"confidence\"],\n",
    "        })\n",
    "    elapsed_ms = int((time.time() - t0)*1000)\n",
    "    return {\"elapsed_ms\": elapsed_ms, \"runs\": outputs}\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_running_loop()\n",
    "    try:\n",
    "        result = await demo_run()\n",
    "    except SyntaxError:\n",
    "        import nest_asyncio; nest_asyncio.apply()\n",
    "        result = loop.run_until_complete(demo_run())\n",
    "except RuntimeError:\n",
    "    result = asyncio.run(demo_run())\n",
    "\n",
    "print(\"Elapsed (ms):\", result[\"elapsed_ms\"])\n",
    "for r in result[\"runs\"]:\n",
    "    print((\n",
    "        f\"\\nCheckpoint: {r['checkpoint']} -> Agent: {r['agent']}\"\n",
    "        f\"\\nTool: {r['tool_result']}\"\n",
    "        f\"\\nLLM:  {r['llm_result']} (conf={r['confidence']:.2f})\"\n",
    "    ).rstrip())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}