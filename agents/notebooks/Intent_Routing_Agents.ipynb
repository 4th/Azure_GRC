{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2918630",
   "metadata": {
    "tags": [
     "TITLE"
    ]
   },
   "source": [
    "# Assembled Notebook â€” SK Agents (Intent Routing)\n",
    "_Generated 2025-11-07T19:10:17.157985Z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09524b16",
   "metadata": {
    "tags": [
     "SETUP"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP]\n",
    "!pip install -U semantic-kernel\n",
    "!pip -q uninstall -y pydrive2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ed444",
   "metadata": {
    "tags": [
     "SETUP-ENV"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP-ENV]\n",
    "import os, getpass\n",
    "os.environ.setdefault('AZURE_OPENAI_ENDPOINT', 'https://4th-openai-resource.openai.azure.com')\n",
    "os.environ.setdefault('AZURE_OPENAI_DEPLOYMENT', 'gpt-35-turbo')\n",
    "os.environ.setdefault('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "if not os.getenv('AZURE_OPENAI_API_KEY'):\n",
    "    os.environ['AZURE_OPENAI_API_KEY'] = getpass.getpass('Enter AZURE_OPENAI_API_KEY (hidden): ').strip()\n",
    "print('Azure OpenAI env ready (key is session-only).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e55aa",
   "metadata": {
    "tags": [
     "KERNEL"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [KERNEL]\n",
    "import os\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service = AzureChatCompletion(\n",
    "    service_id='azure',\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
    "    endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    ")\n",
    "kernel.add_service(service)\n",
    "print('Kernel ready (Azure OpenAI)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31892a23",
   "metadata": {
    "tags": [
     "TOOLS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [TOOLS]\n",
    "\n",
    "def tool_hybrid_search_bm25_vector(**kwargs):\n",
    "    \"\"\"Hybrid search (BM25+Vector) integration placeholder.\"\"\"\n",
    "    return \"stub:Hybrid search (BM25+Vector) \" + str(kwargs)\n",
    "\n",
    "def tool_build_grounding_packet_citations(**kwargs):\n",
    "    \"\"\"Build grounding packet + citations integration placeholder.\"\"\"\n",
    "    return \"stub:Build grounding packet + citations \" + str(kwargs)\n",
    "\n",
    "def tool_rerank(**kwargs):\n",
    "    \"\"\"Rerank integration placeholder.\"\"\"\n",
    "    return \"stub:Rerank \" + str(kwargs)\n",
    "\n",
    "def tool_tool_registry_allowlist(**kwargs):\n",
    "    \"\"\"Tool registry (allowlist) integration placeholder.\"\"\"\n",
    "    return \"stub:Tool registry (allowlist) \" + str(kwargs)\n",
    "\n",
    "def tool_execute_tool_call_s(**kwargs):\n",
    "    \"\"\"Execute tool call(s) integration placeholder.\"\"\"\n",
    "    return \"stub:Execute tool call(s) \" + str(kwargs)\n",
    "\n",
    "\n",
    "TOOLS = {\n",
    "\n",
    "    'tool_hybrid_search_bm25_vector': tool_hybrid_search_bm25_vector,\n",
    "\n",
    "    'tool_build_grounding_packet_citations': tool_build_grounding_packet_citations,\n",
    "\n",
    "    'tool_rerank': tool_rerank,\n",
    "\n",
    "    'tool_tool_registry_allowlist': tool_tool_registry_allowlist,\n",
    "\n",
    "    'tool_execute_tool_call_s': tool_execute_tool_call_s,\n",
    "\n",
    "}\n",
    "print('Tools:', list(TOOLS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163bae02",
   "metadata": {
    "tags": [
     "AGENTS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [AGENTS]\n",
    "\n",
    "class Agent_receive_user_utterance:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Receive user utterance\"\n",
    "        self.system_message = \"You are the Receive user utterance capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Receive user utterance stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_nlu_intent_entities:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"NLU: intent + entities\"\n",
    "        self.system_message = \"You are the NLU: intent + entities capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[NLU: intent + entities stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_call_orchestrate:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Call /orchestrate\"\n",
    "        self.system_message = \"You are the Call /orchestrate capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Call /orchestrate stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_render_answer_to_user:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Render answer to user\"\n",
    "        self.system_message = \"You are the Render answer to user capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Render answer to user stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_authz_rate_limit_headers:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"AuthZ/Rate-limit/Headers\"\n",
    "        self.system_message = \"You are the AuthZ/Rate-limit/Headers capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[AuthZ/Rate-limit/Headers stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_route_to_orchestrator:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Route to orchestrator\"\n",
    "        self.system_message = \"You are the Route to orchestrator capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Route to orchestrator stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_plan_decompose_task:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Plan: decompose task\"\n",
    "        self.system_message = \"You are the Plan: decompose task capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Plan: decompose task stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_budgets_step_caps:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Budgets / step caps\"\n",
    "        self.system_message = \"You are the Budgets / step caps capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Budgets / step caps stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_graph_flow_branching_crew:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Graph flow: branching/crew\"\n",
    "        self.system_message = \"You are the Graph flow: branching/crew capability agent.\"\n",
    "        self.skills = [\"tool_hybrid_search_bm25_vector\", \"tool_tool_registry_allowlist\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Graph flow: branching/crew stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_merge_partial_results:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Merge partial results\"\n",
    "        self.system_message = \"You are the Merge partial results capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Merge partial results stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "\n",
    "# Instances\n",
    "\n",
    "agent_receive_user_utterance = Agent_receive_user_utterance(kernel)\n",
    "\n",
    "agent_nlu_intent_entities = Agent_nlu_intent_entities(kernel)\n",
    "\n",
    "agent_call_orchestrate = Agent_call_orchestrate(kernel)\n",
    "\n",
    "agent_render_answer_to_user = Agent_render_answer_to_user(kernel)\n",
    "\n",
    "agent_authz_rate_limit_headers = Agent_authz_rate_limit_headers(kernel)\n",
    "\n",
    "agent_route_to_orchestrator = Agent_route_to_orchestrator(kernel)\n",
    "\n",
    "agent_plan_decompose_task = Agent_plan_decompose_task(kernel)\n",
    "\n",
    "agent_budgets_step_caps = Agent_budgets_step_caps(kernel)\n",
    "\n",
    "agent_graph_flow_branching_crew = Agent_graph_flow_branching_crew(kernel)\n",
    "\n",
    "agent_merge_partial_results = Agent_merge_partial_results(kernel)\n",
    "\n",
    "print('Agents:', ['agent_receive_user_utterance', 'agent_nlu_intent_entities', 'agent_call_orchestrate', 'agent_render_answer_to_user', 'agent_authz_rate_limit_headers', 'agent_route_to_orchestrator', 'agent_plan_decompose_task', 'agent_budgets_step_caps', 'agent_graph_flow_branching_crew', 'agent_merge_partial_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0dda7",
   "metadata": {
    "tags": [
     "WIRES"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [WIRES]\n",
    "WIRES = {\n",
    "  \"Receive user utterance\": {\n",
    "    \"tools\": []\n",
    "  },\n",
    "  \"NLU: intent + entities\": {\n",
    "    \"tools\": []\n",
    "  },\n",
    "  \"Call /orchestrate\": {\n",
    "    \"tools\": []\n",
    "  },\n",
    "  \"Render answer to user\": {\n",
    "    \"tools\": []\n",
    "  },\n",
    "  \"AuthZ/Rate-limit/Headers\": {\n",
    "    \"tools\": []\n",
    "  },\n",
    "  \"Route to orchestrator\": {\n",
    "    \"tools\": []\n",
    "  },\n",
    "  \"Plan: decompose task\": {\n",
    "    \"tools\": []\n",
    "  },\n",
    "  \"Budgets / step caps\": {\n",
    "    \"tools\": []\n",
    "  },\n",
    "  \"Graph flow: branching/crew\": {\n",
    "    \"tools\": [\n",
    "      \"tool_hybrid_search_bm25_vector\",\n",
    "      \"tool_tool_registry_allowlist\"\n",
    "    ]\n",
    "  },\n",
    "  \"Merge partial results\": {\n",
    "    \"tools\": []\n",
    "  }\n",
    "}\n",
    "print('Wiring entries:', len(WIRES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca527e",
   "metadata": {
    "tags": [
     "DEMO"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# %% [DEMO]\n",
    "import os, getpass, types, asyncio\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "os.environ.setdefault(\"AZURE_OPENAI_ENDPOINT\",    \"https://4th-openai-resource.openai.azure.com\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_DEPLOYMENT\",  \"gpt-35-turbo\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\")\n",
    "if not os.getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter AZURE_OPENAI_API_KEY (hidden): \").strip()\n",
    "\n",
    "try:\n",
    "    kernel\n",
    "except NameError:\n",
    "    kernel = Kernel()\n",
    "try:\n",
    "    kernel.remove_service(\"azure\")\n",
    "except Exception:\n",
    "    pass\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=\"azure\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "))\n",
    "\n",
    "async def _run_with_azure(self, user_text: str):\n",
    "    prompt = (getattr(self, \"system_message\", \"\") or \"\") + \"\\\\n\\\\nUser: \" + str(user_text)\n",
    "    result = await self.kernel.invoke_prompt(prompt, service_id=\"azure\")\n",
    "    return str(result)\n",
    "\n",
    "patched = []\n",
    "for name, obj in list(globals().items()):\n",
    "    if name.startswith(\"agent_\"):\n",
    "        try:\n",
    "            obj.kernel = kernel\n",
    "            obj.run = types.MethodType(_run_with_azure, obj)\n",
    "            patched.append(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "print(\"Patched run() for:\", patched if patched else \"(none)\")\n",
    "\n",
    "async def demo():\n",
    "    candidates = [v for k,v in globals().items() if k.startswith(\"agent_\") and getattr(v, \"skills\", None)]\n",
    "    agent = candidates[0] if candidates else globals()[next((n for n in sorted(globals()) if n.startswith(\"agent_\")), None)]\n",
    "    print(\"Agent:\", getattr(agent, \"name\", \"(unknown)\"))\n",
    "    tools = agent.available_tools() if hasattr(agent, \"available_tools\") else []\n",
    "    print(\"Tools:\", tools)\n",
    "    if tools:\n",
    "        print(\"Tool demo:\", tools[0], \"->\", agent.call(tools[0], example=\"value\"))\n",
    "    print(\"LLM demo:\")\n",
    "    try:\n",
    "        out = await agent.run(\"Briefly describe your role in the routing pipeline.\")\n",
    "        print(out)\n",
    "    except Exception as e:\n",
    "        print(\"[demo] invoke failed:\", e)\n",
    "\n",
    "await demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
