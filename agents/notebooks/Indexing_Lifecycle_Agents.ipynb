{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4374fc83",
   "metadata": {
    "tags": [
     "TITLE"
    ]
   },
   "source": [
    "# Assembled Notebook — Indexing Lifecycle Agents\n",
    "_Generated 2025-11-07T21:37:08.618064Z_\n",
    "\n",
    "> Agents and tools synthesized from your indexing lifecycle diagram (not embedded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dc2669",
   "metadata": {
    "tags": [
     "SETUP"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP]\n",
    "!pip install -U semantic-kernel\n",
    "!pip -q uninstall -y pydrive2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5bc6e",
   "metadata": {
    "tags": [
     "SETUP-ENV"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP-ENV]\n",
    "import os, getpass\n",
    "os.environ.setdefault('AZURE_OPENAI_ENDPOINT', 'https://4th-openai-resource.openai.azure.com')\n",
    "os.environ.setdefault('AZURE_OPENAI_DEPLOYMENT', 'gpt-35-turbo')\n",
    "os.environ.setdefault('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "if not os.getenv('AZURE_OPENAI_API_KEY'):\n",
    "    os.environ['AZURE_OPENAI_API_KEY'] = getpass.getpass('Enter AZURE_OPENAI_API_KEY (hidden): ').strip()\n",
    "print('Azure OpenAI env ready (key is session-only).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0dee06",
   "metadata": {
    "tags": [
     "KERNEL"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [KERNEL]\n",
    "import os\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service = AzureChatCompletion(\n",
    "    service_id='azure',\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
    "    endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    ")\n",
    "kernel.add_service(service)\n",
    "print('Kernel ready (Azure OpenAI)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41136927",
   "metadata": {
    "tags": [
     "TOOLS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [TOOLS]\n",
    "\n",
    "def tool_queue_push(**kwargs):\n",
    "    \"\"\"Push a work item to the queue with priority & scope.\"\"\"\n",
    "    return \"stub:queue_push \" + str(kwargs)\n",
    "\n",
    "def tool_queue_pop(**kwargs):\n",
    "    \"\"\"Pop/peek a work item for a worker.\"\"\"\n",
    "    return \"stub:queue_pop \" + str(kwargs)\n",
    "\n",
    "def tool_crawl(**kwargs):\n",
    "    \"\"\"Fetch content from a source URI; return bytes/etag/last-mod.\"\"\"\n",
    "    return \"stub:crawl \" + str(kwargs)\n",
    "\n",
    "def tool_parse(**kwargs):\n",
    "    \"\"\"Parse bytes → text + metadata; extract mime/sections/pages.\"\"\"\n",
    "    return \"stub:parse \" + str(kwargs)\n",
    "\n",
    "def tool_diff(**kwargs):\n",
    "    \"\"\"Compare etag/last-mod/hash; return changed: bool and reason.\"\"\"\n",
    "    return \"stub:diff \" + str(kwargs)\n",
    "\n",
    "def tool_chunk(**kwargs):\n",
    "    \"\"\"Split text into ordered chunks with size/overlap; count tokens.\"\"\"\n",
    "    return \"stub:chunk \" + str(kwargs)\n",
    "\n",
    "def tool_embed(**kwargs):\n",
    "    \"\"\"Generate embeddings for chunks (model configurable).\"\"\"\n",
    "    return \"stub:embed \" + str(kwargs)\n",
    "\n",
    "def tool_upsert_index(**kwargs):\n",
    "    \"\"\"Upsert vector+BM25 docs into AI Search.\"\"\"\n",
    "    return \"stub:upsert_index \" + str(kwargs)\n",
    "\n",
    "def tool_catalog(**kwargs):\n",
    "    \"\"\"Maintain document→chunks mapping and states.\"\"\"\n",
    "    return \"stub:catalog \" + str(kwargs)\n",
    "\n",
    "def tool_tombstone(**kwargs):\n",
    "    \"\"\"Mark stale chunks as tombstoned and propagate to index.\"\"\"\n",
    "    return \"stub:tombstone \" + str(kwargs)\n",
    "\n",
    "def tool_stats(**kwargs):\n",
    "    \"\"\"Compute distribution stats and cosine shift vs. baseline.\"\"\"\n",
    "    return \"stub:stats \" + str(kwargs)\n",
    "\n",
    "def tool_drift_check(**kwargs):\n",
    "    \"\"\"Compare stats vs thresholds; return drift flag + targets.\"\"\"\n",
    "    return \"stub:drift_check \" + str(kwargs)\n",
    "\n",
    "def tool_trace_log(**kwargs):\n",
    "    \"\"\"Append telemetry event (trace_id, stage, latency, cost).\"\"\"\n",
    "    return \"stub:trace_log \" + str(kwargs)\n",
    "\n",
    "def tool_alert(**kwargs):\n",
    "    \"\"\"Raise alert (failures, drift, quota).\"\"\"\n",
    "    return \"stub:alert \" + str(kwargs)\n",
    "\n",
    "def tool_audit(**kwargs):\n",
    "    \"\"\"Append audit entry (who/when/what).\"\"\"\n",
    "    return \"stub:audit \" + str(kwargs)\n",
    "\n",
    "def tool_blob_store(**kwargs):\n",
    "    \"\"\"Put/get raw and text artifacts in blob storage.\"\"\"\n",
    "    return \"stub:blob_store \" + str(kwargs)\n",
    "\n",
    "\n",
    "TOOLS = {\n",
    "\n",
    "    'tool_queue_push': tool_queue_push,\n",
    "\n",
    "    'tool_queue_pop': tool_queue_pop,\n",
    "\n",
    "    'tool_crawl': tool_crawl,\n",
    "\n",
    "    'tool_parse': tool_parse,\n",
    "\n",
    "    'tool_diff': tool_diff,\n",
    "\n",
    "    'tool_chunk': tool_chunk,\n",
    "\n",
    "    'tool_embed': tool_embed,\n",
    "\n",
    "    'tool_upsert_index': tool_upsert_index,\n",
    "\n",
    "    'tool_catalog': tool_catalog,\n",
    "\n",
    "    'tool_tombstone': tool_tombstone,\n",
    "\n",
    "    'tool_stats': tool_stats,\n",
    "\n",
    "    'tool_drift_check': tool_drift_check,\n",
    "\n",
    "    'tool_trace_log': tool_trace_log,\n",
    "\n",
    "    'tool_alert': tool_alert,\n",
    "\n",
    "    'tool_audit': tool_audit,\n",
    "\n",
    "    'tool_blob_store': tool_blob_store,\n",
    "\n",
    "}\n",
    "print('Tools:', list(TOOLS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc079d5",
   "metadata": {
    "tags": [
     "AGENTS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [AGENTS]\n",
    "\n",
    "class Agent_planner:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Ingest Planner\"\n",
    "        self.system_message = \"You are the Ingest Planner capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_queue_push\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Ingest Planner stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_queue_mgr:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Work Queue Manager\"\n",
    "        self.system_message = \"You are the Work Queue Manager capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_queue_pop\", \"tool_queue_push\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Work Queue Manager stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_crawler:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Crawler\"\n",
    "        self.system_message = \"You are the Crawler capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_crawl\", \"tool_blob_store\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Crawler stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_parser:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Parser/Extractor\"\n",
    "        self.system_message = \"You are the Parser/Extractor capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_parse\", \"tool_blob_store\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Parser/Extractor stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_differ:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Delta Detector\"\n",
    "        self.system_message = \"You are the Delta Detector capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_diff\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Delta Detector stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_chunker:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Chunker\"\n",
    "        self.system_message = \"You are the Chunker capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_chunk\", \"tool_catalog\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Chunker stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_embedder:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Embedder\"\n",
    "        self.system_message = \"You are the Embedder capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_embed\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Embedder stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_indexer:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Indexer\"\n",
    "        self.system_message = \"You are the Indexer capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_upsert_index\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Indexer stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_cataloger:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Catalog Updater\"\n",
    "        self.system_message = \"You are the Catalog Updater capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_catalog\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Catalog Updater stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_tombstoner:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Tombstoner\"\n",
    "        self.system_message = \"You are the Tombstoner capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_tombstone\", \"tool_catalog\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Tombstoner stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_driftmon:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Drift Monitor\"\n",
    "        self.system_message = \"You are the Drift Monitor capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_stats\", \"tool_drift_check\", \"tool_queue_push\", \"tool_trace_log\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Drift Monitor stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_observer:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Observability Agent\"\n",
    "        self.system_message = \"You are the Observability Agent capability agent for indexing lifecycle.\"\n",
    "        self.skills = [\"tool_trace_log\", \"tool_alert\", \"tool_audit\"]\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Observability Agent stub] Adjust SK call. Error: {e}\"\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "\n",
    "# Instances\n",
    "\n",
    "agent_planner = Agent_planner(kernel)\n",
    "\n",
    "agent_queue_mgr = Agent_queue_mgr(kernel)\n",
    "\n",
    "agent_crawler = Agent_crawler(kernel)\n",
    "\n",
    "agent_parser = Agent_parser(kernel)\n",
    "\n",
    "agent_differ = Agent_differ(kernel)\n",
    "\n",
    "agent_chunker = Agent_chunker(kernel)\n",
    "\n",
    "agent_embedder = Agent_embedder(kernel)\n",
    "\n",
    "agent_indexer = Agent_indexer(kernel)\n",
    "\n",
    "agent_cataloger = Agent_cataloger(kernel)\n",
    "\n",
    "agent_tombstoner = Agent_tombstoner(kernel)\n",
    "\n",
    "agent_driftmon = Agent_driftmon(kernel)\n",
    "\n",
    "agent_observer = Agent_observer(kernel)\n",
    "\n",
    "print('Agents:', ['agent_planner', 'agent_queue_mgr', 'agent_crawler', 'agent_parser', 'agent_differ', 'agent_chunker', 'agent_embedder', 'agent_indexer', 'agent_cataloger', 'agent_tombstoner', 'agent_driftmon', 'agent_observer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e06660",
   "metadata": {
    "tags": [
     "WIRES"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [WIRES]\n",
    "WIRES = {\n",
    "  \"Ingest Planner\": {\n",
    "    \"tools\": [\n",
    "      \"tool_queue_push\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Work Queue Manager\": {\n",
    "    \"tools\": [\n",
    "      \"tool_queue_pop\",\n",
    "      \"tool_queue_push\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Crawler\": {\n",
    "    \"tools\": [\n",
    "      \"tool_crawl\",\n",
    "      \"tool_blob_store\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Parser/Extractor\": {\n",
    "    \"tools\": [\n",
    "      \"tool_parse\",\n",
    "      \"tool_blob_store\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Delta Detector\": {\n",
    "    \"tools\": [\n",
    "      \"tool_diff\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Chunker\": {\n",
    "    \"tools\": [\n",
    "      \"tool_chunk\",\n",
    "      \"tool_catalog\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Embedder\": {\n",
    "    \"tools\": [\n",
    "      \"tool_embed\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Indexer\": {\n",
    "    \"tools\": [\n",
    "      \"tool_upsert_index\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Catalog Updater\": {\n",
    "    \"tools\": [\n",
    "      \"tool_catalog\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Tombstoner\": {\n",
    "    \"tools\": [\n",
    "      \"tool_tombstone\",\n",
    "      \"tool_catalog\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Drift Monitor\": {\n",
    "    \"tools\": [\n",
    "      \"tool_stats\",\n",
    "      \"tool_drift_check\",\n",
    "      \"tool_queue_push\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Observability Agent\": {\n",
    "    \"tools\": [\n",
    "      \"tool_trace_log\",\n",
    "      \"tool_alert\",\n",
    "      \"tool_audit\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "print('Wiring entries:', len(WIRES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68370b8",
   "metadata": {
    "tags": [
     "DEMO"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# %% [DEMO]\n",
    "import os, getpass, types, asyncio\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "os.environ.setdefault(\"AZURE_OPENAI_ENDPOINT\",    \"https://4th-openai-resource.openai.azure.com\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_DEPLOYMENT\",  \"gpt-35-turbo\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\")\n",
    "if not os.getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter AZURE_OPENAI_API_KEY (hidden): \").strip()\n",
    "\n",
    "try:\n",
    "    kernel\n",
    "except NameError:\n",
    "    kernel = Kernel()\n",
    "try:\n",
    "    kernel.remove_service(\"azure\")\n",
    "except Exception:\n",
    "    pass\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=\"azure\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "))\n",
    "\n",
    "async def _run_with_azure(self, user_text: str):\n",
    "    prompt = (getattr(self, \"system_message\", \"\") or \"\") + \"\\\\n\\\\nUser: \" + str(user_text)\n",
    "    result = await self.kernel.invoke_prompt(prompt, service_id=\"azure\")\n",
    "    return str(result)\n",
    "\n",
    "patched = []\n",
    "for name, obj in list(globals().items()):\n",
    "    if name.startswith(\"agent_\"):\n",
    "        try:\n",
    "            obj.kernel = kernel\n",
    "            obj.run = types.MethodType(_run_with_azure, obj)\n",
    "            patched.append(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "print(\"Patched run() for:\", patched if patched else \"(none)\")\n",
    "\n",
    "async def demo():\n",
    "    planner = globals().get(\"agent_planner\")\n",
    "    chunker = globals().get(\"agent_chunker\")\n",
    "    embedder = globals().get(\"agent_embedder\")\n",
    "    indexer = globals().get(\"agent_indexer\")\n",
    "\n",
    "    for label, agent in [(\"planner\", planner), (\"chunker\", chunker), (\"embedder\", embedder), (\"indexer\", indexer)]:\n",
    "        print(f\\\"Agent ({label}):\\\", getattr(agent, \"name\", \"(missing)\"))\n",
    "        if hasattr(agent, \"available_tools\"):\n",
    "            print(f\\\"Tools ({label}):\\\", agent.available_tools())\n",
    "            if agent.available_tools():\n",
    "                t0 = agent.available_tools()[0]\n",
    "                print(f\\\"Call {t0} ->\\\", agent.call(t0, example=\"value\"))\n",
    "    print(\"LLM demo:\")\n",
    "    try:\n",
    "        out = await planner.run(\"In one sentence, outline the indexing lifecycle from crawl to upsert.\")\n",
    "        print(out)\n",
    "    except Exception as e:\n",
    "        print(\"[demo] invoke failed:\", e)\n",
    "\n",
    "await demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
