{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Risk / Control Heatmap — Agents Notebook\nGenerated: **2025-11-09T12:29:17Z**\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "```mermaid\nflowchart LR \n  subgraph GRID[\"Heatmap (Risk severity by area)\"]\n    direction TB\n    H0[Areas →]\n    H1[PVA / APIM]\n    H2[Orchestrator\\n(SK / LangGraph)]\n    H3[Tools / RAG]\n    H4[Data Plane\\n(AOAI / Search / Storage)]\n    H5[Ops / CI-CD]\n    L0[Latency]\n    L1(( )):::med\n    L2(( )):::high\n    L3(( )):::high\n    L4(( )):::med\n    L5(( )):::med\n    G0[Grounding Accuracy]\n    G1(( )):::low\n    G2(( )):::med\n    G3(( )):::crit\n    G4(( )):::med\n    G5(( )):::low\n    C0[Cost]\n    C1(( )):::low\n    C2(( )):::med\n    C3(( )):::high\n    C4(( )):::high\n    C5(( )):::med\n    R0[Data Residency]\n    R1(( )):::low\n    R2(( )):::med\n    R3(( )):::med\n    R4(( )):::crit\n    R5(( )):::med\n  end\n  H0 --- H1 --- H2 --- H3 --- H4 --- H5\n  L0 --- L1 --- L2 --- L3 --- L4 --- L5\n  G0 --- G1 --- G2 --- G3 --- G4 --- G5\n  C0 --- C1 --- C2 --- C3 --- C4 --- C5\n  R0 --- R1 --- R2 --- R3 --- R4 --- R5\n  subgraph CTRL[\"Key Controls (by risk)\"]\n    direction TB\n    CLAT[Latency Controls:\\\\n• APIM caching / retries\\\\n• Concurrent graph tuning\\\\n• p95 SLO with canary gates]\n    CGRA[Grounding Controls:\\\\n• Hybrid search + filters\\\\n• Citation coverage thresholds\\\\n• Index drift detection / reindex]\n    CCST[Cost Controls:\\\\n• Token meters & caps\\\\n• Cheaper model fallback\\\\n• Per-intent $/turn budgets]\n    CDRS[Residency Controls:\\\\n• Private Endpoints (PE)\\\\n• Regional pinning & DLP\\\\n• RBAC + data tagging]\n  end\n  L2 -.-> CLAT\n  L3 -.-> CLAT\n  G3 -.-> CGRA\n  C3 -.-> CCST\n  C4 -.-> CCST\n  R4 -.-> CDRS\n  subgraph LEGEND[\"Legend\"]\n    direction LR\n    LG1[Low]:::low\n    LG2[Med]:::med\n    LG3[High]:::high\n    LG4[Crit]:::crit\n  end\n  classDef low  fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20;\n  classDef med  fill:#fff8e1,stroke:#f9a825,stroke-width:2px,color:#7a4f01;\n  classDef high fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#7f1d1d;\n  classDef crit fill:#f3e8ff,stroke:#6a1b9a,stroke-width:2px,color:#4a148c;\n  class GRID,CTRL,LEGEND low\n```\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## SETUP\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# %% [SETUP]\n!pip -q install -U semantic-kernel\nprint(\"Installed: semantic-kernel\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## SETUP-ENV\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# %% [SETUP-ENV]\nimport os, getpass\nos.environ.setdefault('AZURE_OPENAI_ENDPOINT', 'https://4th-openai-resource.openai.azure.com')\nos.environ.setdefault('AZURE_OPENAI_DEPLOYMENT', 'gpt-35-turbo')\nos.environ.setdefault('AZURE_OPENAI_API_VERSION', '2024-10-21')\nif not os.getenv('AZURE_OPENAI_API_KEY'):\n    os.environ['AZURE_OPENAI_API_KEY'] = getpass.getpass('Enter AZURE_OPENAI_API_KEY (hidden): ').strip()\nprint('Azure OpenAI env ready (key is session-only).')\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## KERNEL\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# %% [KERNEL]\nimport os\nfrom semantic_kernel import Kernel\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\nkernel = Kernel()\ntry:\n    service = AzureChatCompletion(\n        service_id=\"azure\",\n        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n        deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n        endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n    )\n    kernel.add_service(service)\n    print(\"Kernel ready (Azure OpenAI).\")\nexcept Exception as e:\n    print(\"Kernel setup warning:\", e)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## TOOLS\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# %% [TOOLS]\ndef tool_apim_caching(**kwargs): return \"stub:APIM caching/retry \" + str(kwargs)\ndef tool_concurrent_graph(**kwargs): return \"stub:Concurrent graph tuning \" + str(kwargs)\ndef tool_grounded_retriever(**kwargs): return \"stub:Hybrid search + filters \" + str(kwargs)\ndef tool_citation_threshold(**kwargs): return \"stub:Citation coverage check \" + str(kwargs)\ndef tool_token_meter(**kwargs): return \"stub:Token meter/caps \" + str(kwargs)\ndef tool_cheaper_model(**kwargs): return \"stub:Cheaper model fallback \" + str(kwargs)\ndef tool_private_endpoints(**kwargs): return \"stub:Private Endpoints usage \" + str(kwargs)\ndef tool_regional_pinning(**kwargs): return \"stub:Regional pinning / DLP \" + str(kwargs)\n\nTOOLS = {\n    \"apim_caching\": tool_apim_caching,\n    \"concurrent_graph\": tool_concurrent_graph,\n    \"grounded_retriever\": tool_grounded_retriever,\n    \"citation_threshold\": tool_citation_threshold,\n    \"token_meter\": tool_token_meter,\n    \"cheaper_model\": tool_cheaper_model,\n    \"private_endpoints\": tool_private_endpoints,\n    \"regional_pinning\": tool_regional_pinning,\n}\nprint(\"Tools:\", list(TOOLS.keys()))\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## AGENTS\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# %% [AGENTS]\nclass Agent:\n    def __init__(self, kernel, name, system_message, skills):\n        self.kernel = kernel\n        self.name = name\n        self.system_message = system_message\n        self.skills = skills or []\n\n    async def run(self, user_text: str) -> str:\n        return f\"[demo:{self.name}] {user_text}\"\n\n    def available_tools(self): return [t for t in self.skills if t in TOOLS]\n    def call(self, tool_name: str, **kwargs):\n        fn = TOOLS.get(tool_name)\n        if not fn: raise ValueError(f\"Tool not found: {tool_name}\")\n        return fn(**kwargs)\n\nagent_pva_apim = Agent(kernel, \"PVA / APIM\", \"Ingress latency and correlation via PVA/APIM.\", [\"apim_caching\"])\nagent_orchestrator = Agent(kernel, \"Orchestrator (SK/LangGraph)\", \"Planning, concurrency, retries.\", [\"concurrent_graph\",\"token_meter\",\"cheaper_model\"])\nagent_tools_rag = Agent(kernel, \"Tools / RAG\", \"Grounding quality and citations.\", [\"grounded_retriever\",\"citation_threshold\"])\nagent_data_plane = Agent(kernel, \"Data Plane (AOAI/Search/Storage)\", \"Residency via PE and pinning.\", [\"private_endpoints\",\"regional_pinning\"])\nagent_ops = Agent(kernel, \"Ops / CI-CD\", \"SLOs and cost posture.\", [\"token_meter\",\"cheaper_model\"])\nprint(\"Agents:\", [a.name for a in [agent_pva_apim, agent_orchestrator, agent_tools_rag, agent_data_plane, agent_ops]])\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## WIRES\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# %% [WIRES]\nROUTES = {\n    \"Latency\": \"pva_apim\",\n    \"Grounding Accuracy\": \"tools_rag\",\n    \"Cost\": \"ops\",\n    \"Data Residency\": \"data_plane\",\n}\nAGENT_INDEX = {\n    \"pva_apim\": agent_pva_apim,\n    \"orchestrator\": agent_orchestrator,\n    \"tools_rag\": agent_tools_rag,\n    \"data_plane\": agent_data_plane,\n    \"ops\": agent_ops,\n}\ndef validate_wiring():\n    problems = []\n    for risk, key in ROUTES.items():\n        agent = AGENT_INDEX.get(key)\n        if not agent: problems.append(f\"{risk} -> missing agent key '{key}'\"); continue\n        if not agent.available_tools(): problems.append(f\"{risk} -> {agent.name} has no available tools\")\n    return problems\n\ntotal_wires = len(ROUTES)\ndistinct_agents = len(set(ROUTES.values()))\nunreferenced_agents = sorted(set(AGENT_INDEX.keys()) - set(ROUTES.values()))\ntargets_by_agent = {}\nfor risk, key in ROUTES.items():\n    targets_by_agent.setdefault(key, []).append(risk)\n\nissues = validate_wiring()\nprint(f\"Wires: {total_wires} (distinct agents: {distinct_agents})\")\nfor agent_key, risks in targets_by_agent.items():\n    agent_name = AGENT_INDEX[agent_key].name\n    print(f\"  - {agent_name} ← {len(risks)} risk(s): {', '.join(risks)}\")\nif unreferenced_agents: print(f\"Unreferenced agents: {', '.join(unreferenced_agents)}\")\nprint(\"Wiring OK\" if not issues else \"Wiring issues:\\n- \" + \"\\n- \".join(issues))\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## DEMO\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# %% [DEMO]\nimport asyncio, time\nasync def demo_run():\n    t0 = time.time()\n    samples = [\n        (\"Latency\", \"p95 latency is spiking in APIM.\"),\n        (\"Grounding Accuracy\", \"Ensure citations cover all key claims.\"),\n        (\"Cost\", \"Cap cost to $0.01 per turn for FAQ.\"),\n        (\"Data Residency\", \"Restrict data plane to region US only via PE.\"),\n    ]\n    outputs = []\n    for risk, text in samples:\n        key = ROUTES[risk]\n        agent = AGENT_INDEX[key]\n        tool_out = None\n        if key == \"pva_apim\":\n            tool_out = agent.call(\"apim_caching\", policy=\"retry-3\", cache_ttl=\"30s\")\n        elif key == \"tools_rag\":\n            tool_out = agent.call(\"grounded_retriever\", k=5, filter=\"tenant:acme\")\n        elif key == \"ops\":\n            tool_out = agent.call(\"token_meter\", cap_tokens=2000)\n        elif key == \"data_plane\":\n            tool_out = agent.call(\"private_endpoints\", services=[\"aoai\",\"search\",\"storage\"])\n        note = await agent.run(text)\n        outputs.append((risk, agent.name, tool_out, note))\n    elapsed_ms = int((time.time() - t0)*1000)\n    return elapsed_ms, outputs\n\ntry:\n    loop = asyncio.get_running_loop()\n    try:\n        elapsed_ms, outputs = await demo_run()\n    except SyntaxError:\n        import nest_asyncio; nest_asyncio.apply()\n        elapsed_ms, outputs = loop.run_until_complete(demo_run())\nexcept RuntimeError:\n    elapsed_ms, outputs = asyncio.run(demo_run())\n\nprint(\"Elapsed (ms):\", elapsed_ms)\nfor risk, agent_name, tool, note in outputs:\n    print(f\"Risk: {risk} → Agent: {agent_name}\\n  Tool: {tool}\\n  Note: {note}\\n\")\n",
      "outputs": [],
      "execution_count": null
    }
  ]
}