{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba44e16",
   "metadata": {
    "tags": [
     "TITLE"
    ]
   },
   "source": [
    "# Assembled Notebook â€” SK Agents (Value Stream)\n",
    "_Generated 2025-11-07T16:51:47.989839Z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec25a3",
   "metadata": {
    "tags": [
     "SETUP"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP]\n",
    "# Install latest Semantic Kernel\n",
    "!pip install -U semantic-kernel\n",
    "!pip -q uninstall -y pydrive2  # avoid OpenSSL/cryptography conflicts in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8163e",
   "metadata": {
    "tags": [
     "SETUP-ENV"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP-ENV]\n",
    "import os, getpass\n",
    "os.environ.setdefault('AZURE_OPENAI_ENDPOINT', 'https://4th-openai-resource.openai.azure.com')\n",
    "os.environ.setdefault('AZURE_OPENAI_DEPLOYMENT', 'gpt-35-turbo')\n",
    "os.environ.setdefault('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "if not os.getenv('AZURE_OPENAI_API_KEY'):\n",
    "    os.environ['AZURE_OPENAI_API_KEY'] = getpass.getpass('Enter AZURE_OPENAI_API_KEY (hidden): ').strip()\n",
    "print('Azure OpenAI env ready (key is session-only).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95e345",
   "metadata": {
    "tags": [
     "KERNEL"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [KERNEL]\n",
    "import os\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service = AzureChatCompletion(\n",
    "    service_id=\"azure\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    # api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),  # optional\n",
    ")\n",
    "kernel.add_service(service)\n",
    "print(\"Kernel ready (Azure OpenAI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ea2c6",
   "metadata": {
    "tags": [
     "TOOLS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [TOOLS]\n",
    "\n",
    "def tool_hybrid_retrieval_bm25_vector(**kwargs):\n",
    "    \"\"\"Hybrid Retrieval (BM25 + Vector) integration placeholder.\"\"\"\n",
    "    # TODO: implement integration with: Hybrid Retrieval (BM25 + Vector)\n",
    "    return \"stub:Hybrid Retrieval (BM25 + Vector) \" + str(kwargs)\n",
    "\n",
    "def tool_reranker(**kwargs):\n",
    "    \"\"\"Reranker integration placeholder.\"\"\"\n",
    "    # TODO: implement integration with: Reranker\n",
    "    return \"stub:Reranker \" + str(kwargs)\n",
    "\n",
    "def tool_llm_inference(**kwargs):\n",
    "    \"\"\"LLM Inference integration placeholder.\"\"\"\n",
    "    # TODO: implement integration with: LLM Inference\n",
    "    return \"stub:LLM Inference \" + str(kwargs)\n",
    "\n",
    "def tool_grounding_packet_builder(**kwargs):\n",
    "    \"\"\"Grounding Packet Builder integration placeholder.\"\"\"\n",
    "    # TODO: implement integration with: Grounding Packet Builder\n",
    "    return \"stub:Grounding Packet Builder \" + str(kwargs)\n",
    "\n",
    "def tool_telemetry_trace_id_latency_cost(**kwargs):\n",
    "    \"\"\"Telemetry (trace_id, latency, cost) integration placeholder.\"\"\"\n",
    "    # TODO: implement integration with: Telemetry (trace_id, latency, cost)\n",
    "    return \"stub:Telemetry (trace_id, latency, cost) \" + str(kwargs)\n",
    "\n",
    "\n",
    "TOOLS = {\n",
    "\n",
    "    'tool_hybrid_retrieval_bm25_vector': tool_hybrid_retrieval_bm25_vector,\n",
    "\n",
    "    'tool_reranker': tool_reranker,\n",
    "\n",
    "    'tool_llm_inference': tool_llm_inference,\n",
    "\n",
    "    'tool_grounding_packet_builder': tool_grounding_packet_builder,\n",
    "\n",
    "    'tool_telemetry_trace_id_latency_cost': tool_telemetry_trace_id_latency_cost,\n",
    "\n",
    "}\n",
    "print('Tools:', list(TOOLS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cba6c7",
   "metadata": {
    "tags": [
     "AGENTS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [AGENTS]\n",
    "\n",
    "class Agent_channel_pva_copilot_web:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Channel (PVA / Copilot / Web)\"\n",
    "        self.system_message = \"You are the Channel (PVA / Copilot / Web) capability agent.\"\n",
    "        self.skills = [\"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Channel (PVA / Copilot / Web) stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_intent_router:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Intent Router\"\n",
    "        self.system_message = \"You are the Intent Router capability agent.\"\n",
    "        self.skills = [\"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Intent Router stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_planner_policy_checks:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Planner / Policy Checks\"\n",
    "        self.system_message = \"You are the Planner / Policy Checks capability agent.\"\n",
    "        self.skills = [\"tool_hybrid_retrieval_bm25_vector\", \"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Planner / Policy Checks stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_hybrid_retrieval_bm25_vector:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Hybrid Retrieval (BM25 + Vector)\"\n",
    "        self.system_message = \"You are the Hybrid Retrieval (BM25 + Vector) capability agent.\"\n",
    "        self.skills = [\"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Hybrid Retrieval (BM25 + Vector) stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_reranker:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Reranker\"\n",
    "        self.system_message = \"You are the Reranker capability agent.\"\n",
    "        self.skills = [\"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Reranker stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_grounding_packet_builder:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Grounding Packet Builder\"\n",
    "        self.system_message = \"You are the Grounding Packet Builder capability agent.\"\n",
    "        self.skills = [\"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Grounding Packet Builder stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_llm_inference:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"LLM Inference\"\n",
    "        self.system_message = \"You are the LLM Inference capability agent.\"\n",
    "        self.skills = [\"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[LLM Inference stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_grounded_answer:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Grounded Answer\"\n",
    "        self.system_message = \"You are the Grounded Answer capability agent.\"\n",
    "        self.skills = [\"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Grounded Answer stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_user_feedback:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"User Feedback\"\n",
    "        self.system_message = \"You are the User Feedback capability agent.\"\n",
    "        self.skills = [\"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[User Feedback stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_eval_factuality_citation_refusal:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Eval (factuality, citation, refusal)\"\n",
    "        self.system_message = \"You are the Eval (factuality, citation, refusal) capability agent.\"\n",
    "        self.skills = [\"tool_telemetry_trace_id_latency_cost\"]\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Eval (factuality, citation, refusal) stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "class Agent_telemetry_trace_id_latency_cost:\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.name = \"Telemetry (trace_id, latency, cost)\"\n",
    "        self.system_message = \"You are the Telemetry (trace_id, latency, cost) capability agent.\"\n",
    "        self.skills = []\n",
    "\n",
    "    async def run(self, user_text: str) -> str:\n",
    "        try:\n",
    "            # The DEMO cell will later patch this call to set service_id='azure' explicitly.\n",
    "            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"[Telemetry (trace_id, latency, cost) stub] Adjust SK call. Error: {e}\"\n",
    "\n",
    "    def available_tools(self):\n",
    "        return [t for t in self.skills if t in TOOLS]\n",
    "\n",
    "    def call(self, tool_name: str, **kwargs):\n",
    "        fn = TOOLS.get(tool_name)\n",
    "        if not fn:\n",
    "            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "        return fn(**kwargs)\n",
    "\n",
    "\n",
    "# Instances\n",
    "\n",
    "agent_channel_pva_copilot_web = Agent_channel_pva_copilot_web(kernel)\n",
    "\n",
    "agent_intent_router = Agent_intent_router(kernel)\n",
    "\n",
    "agent_planner_policy_checks = Agent_planner_policy_checks(kernel)\n",
    "\n",
    "agent_hybrid_retrieval_bm25_vector = Agent_hybrid_retrieval_bm25_vector(kernel)\n",
    "\n",
    "agent_reranker = Agent_reranker(kernel)\n",
    "\n",
    "agent_grounding_packet_builder = Agent_grounding_packet_builder(kernel)\n",
    "\n",
    "agent_llm_inference = Agent_llm_inference(kernel)\n",
    "\n",
    "agent_grounded_answer = Agent_grounded_answer(kernel)\n",
    "\n",
    "agent_user_feedback = Agent_user_feedback(kernel)\n",
    "\n",
    "agent_eval_factuality_citation_refusal = Agent_eval_factuality_citation_refusal(kernel)\n",
    "\n",
    "agent_telemetry_trace_id_latency_cost = Agent_telemetry_trace_id_latency_cost(kernel)\n",
    "\n",
    "print('Agents:', ['agent_channel_pva_copilot_web', 'agent_intent_router', 'agent_planner_policy_checks', 'agent_hybrid_retrieval_bm25_vector', 'agent_reranker', 'agent_grounding_packet_builder', 'agent_llm_inference', 'agent_grounded_answer', 'agent_user_feedback', 'agent_eval_factuality_citation_refusal', 'agent_telemetry_trace_id_latency_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028af40c",
   "metadata": {
    "tags": [
     "WIRES"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [WIRES]\n",
    "WIRES = {\n",
    "  \"Channel (PVA / Copilot / Web)\": {\n",
    "    \"tools\": [\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"Intent Router\": {\n",
    "    \"tools\": [\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"Planner / Policy Checks\": {\n",
    "    \"tools\": [\n",
    "      \"tool_hybrid_retrieval_bm25_vector\",\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"Hybrid Retrieval (BM25 + Vector)\": {\n",
    "    \"tools\": [\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"Reranker\": {\n",
    "    \"tools\": [\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"Grounding Packet Builder\": {\n",
    "    \"tools\": [\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"LLM Inference\": {\n",
    "    \"tools\": [\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"Grounded Answer\": {\n",
    "    \"tools\": [\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"User Feedback\": {\n",
    "    \"tools\": [\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"Eval (factuality, citation, refusal)\": {\n",
    "    \"tools\": [\n",
    "      \"tool_telemetry_trace_id_latency_cost\"\n",
    "    ]\n",
    "  },\n",
    "  \"Telemetry (trace_id, latency, cost)\": {\n",
    "    \"tools\": []\n",
    "  }\n",
    "}\n",
    "print('Wiring entries:', len(WIRES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bfeb1",
   "metadata": {
    "tags": [
     "DEMO"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [DEMO]\n",
    "import os, getpass, types, asyncio\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# 1) Ensure env\n",
    "os.environ.setdefault(\"AZURE_OPENAI_ENDPOINT\",    \"https://4th-openai-resource.openai.azure.com\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_DEPLOYMENT\",  \"gpt-35-turbo\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\")\n",
    "if not os.getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter AZURE_OPENAI_API_KEY (hidden): \").strip()\n",
    "\n",
    "# 2) Ensure kernel exists and has azure service\n",
    "try:\n",
    "    kernel\n",
    "except NameError:\n",
    "    kernel = Kernel()\n",
    "try:\n",
    "    kernel.remove_service(\"azure\")\n",
    "except Exception:\n",
    "    pass\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=\"azure\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "))\n",
    "\n",
    "# 3) Rebind all agents to this kernel & patch run() to force service_id=\"azure\"\n",
    "async def _run_with_azure(self, user_text: str):\n",
    "    prompt = (getattr(self, \"system_message\", \"\") or \"\") + \"\\n\\nUser: \" + str(user_text)\n",
    "    result = await self.kernel.invoke_prompt(prompt, service_id=\"azure\")\n",
    "    return str(result)\n",
    "\n",
    "rebound, patched = [], []\n",
    "for name, obj in list(globals().items()):\n",
    "    if name.startswith(\"agent_\"):\n",
    "        try:\n",
    "            obj.kernel = kernel\n",
    "            rebound.append(name)\n",
    "            obj.run = types.MethodType(_run_with_azure, obj)\n",
    "            patched.append(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "print(\"Rebound agents:\", rebound if rebound else \"(none)\")\n",
    "print(\"Patched run() for:\", patched if patched else \"(none)\")\n",
    "\n",
    "# 4) Demo: use first agent, try a tool, then an LLM call\n",
    "async def demo():\n",
    "    agent_name = next((n for n in sorted(globals()) if n.startswith(\"agent_\")), None)\n",
    "    if not agent_name:\n",
    "        print(\"No agent_* instances found.\"); return\n",
    "    agent = globals()[agent_name]\n",
    "    print(\"Agent:\", getattr(agent, \"name\", agent_name))\n",
    "\n",
    "    tools = agent.available_tools() if hasattr(agent, \"available_tools\") else []\n",
    "    print(\"Tools:\", tools)\n",
    "    if tools:\n",
    "        try:\n",
    "            print(\"Tool demo:\", tools[0], \"->\", agent.call(tools[0], example=\"value\"))\n",
    "        except Exception as e:\n",
    "            print(\"Tool call failed:\", e)\n",
    "\n",
    "    print(\"LLM demo:\")\n",
    "    try:\n",
    "        out = await agent.run(\"Summarize your role in one sentence.\")\n",
    "        print(out)\n",
    "    except Exception as e:\n",
    "        print(\"[demo] invoke failed:\", e)\n",
    "\n",
    "await demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
