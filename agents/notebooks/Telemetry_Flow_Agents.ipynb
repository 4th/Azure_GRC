{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa55fed9",
   "metadata": {
    "tags": [
     "TITLE"
    ]
   },
   "source": [
    "# Assembled Notebook — Telemetry Flow Agents\n",
    "_Generated 2025-11-08T02:45:50.607137Z_\n",
    "\n",
    "Only runnable Python is produced; your Mermaid diagram is not embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e6d135",
   "metadata": {
    "tags": [
     "SETUP"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP]\n",
    "!pip install -U semantic-kernel\n",
    "!pip -q uninstall -y pydrive2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e9787",
   "metadata": {
    "tags": [
     "SETUP-ENV"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [SETUP-ENV]\n",
    "import os, getpass\n",
    "os.environ.setdefault('AZURE_OPENAI_ENDPOINT', 'https://4th-openai-resource.openai.azure.com')\n",
    "os.environ.setdefault('AZURE_OPENAI_DEPLOYMENT', 'gpt-35-turbo')\n",
    "os.environ.setdefault('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "if not os.getenv('AZURE_OPENAI_API_KEY'):\n",
    "    os.environ['AZURE_OPENAI_API_KEY'] = getpass.getpass('Enter AZURE_OPENAI_API_KEY (hidden): ').strip()\n",
    "print('Azure OpenAI env ready (key is session-only).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964c3d4",
   "metadata": {
    "tags": [
     "KERNEL"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [KERNEL]\n",
    "import os\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "kernel = Kernel()\n",
    "service = AzureChatCompletion(\n",
    "    service_id='azure',\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
    "    endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    ")\n",
    "kernel.add_service(service)\n",
    "print('Kernel ready (Azure OpenAI)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65cae5",
   "metadata": {
    "tags": [
     "TOOLS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [TOOLS]\n",
    "\n",
    "import time, uuid, random\n",
    "\n",
    "_COST = {'tokens_in':0,'tokens_out':0,'cost':0.0}\n",
    "\n",
    "_TRACE = {'events':[], 'trace_id': None}\n",
    "\n",
    "def tool_trace_start(**kwargs):\n",
    "    \"\"\"Start or propagate a trace context (trace_id, span_id, baggage).\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"trace_start\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'trace_start' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'trace_start' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_trace_log(**kwargs):\n",
    "    \"\"\"Log an event to OpenTelemetry exporter (stubbed).\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"trace_log\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'trace_log' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'trace_log' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_trace_end(**kwargs):\n",
    "    \"\"\"End span and emit metrics (latency, tokens, cost).\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"trace_end\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'trace_end' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'trace_end' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_apim_set_correlation(**kwargs):\n",
    "    \"\"\"Simulate APIM inbound/outbound correlation headers.\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"apim_set_correlation\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'apim_set_correlation' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'apim_set_correlation' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_sk_plan_record(**kwargs):\n",
    "    \"\"\"Record SK planner decisions (tools, retries) into trace.\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"sk_plan_record\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'sk_plan_record' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'sk_plan_record' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_lg_node_event(**kwargs):\n",
    "    \"\"\"Record LangGraph node execution event.\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"lg_node_event\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'lg_node_event' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'lg_node_event' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_rag_query(**kwargs):\n",
    "    \"\"\"Simulate AI Search retrieval (records query metrics only).\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"rag_query\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'rag_query' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'rag_query' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_http_request(**kwargs):\n",
    "    \"\"\"Simulate HTTP tool call (latency/status/body_size only).\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"http_request\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'http_request' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'http_request' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_soap_action(**kwargs):\n",
    "    \"\"\"Simulate SOAP tool call (action/latency/faults).\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"soap_action\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'soap_action' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'soap_action' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_calc_eval(**kwargs):\n",
    "    \"\"\"Simulate safe calc/eval tool (compute time only).\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"calc_eval\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'calc_eval' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'calc_eval' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_cost_meter(**kwargs):\n",
    "    \"\"\"Accumulate token usage and cost.\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"cost_meter\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'cost_meter' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'cost_meter' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "def tool_eval_quality(**kwargs):\n",
    "    \"\"\"Record evaluation results (quality/safety).\"\"\"\n",
    "    now = time.time()\n",
    "    evt = dict(kind=\"eval_quality\", ts=now, **kwargs)\n",
    "    global _TRACE, _COST\n",
    "    if 'eval_quality' == 'trace_start':\n",
    "        _TRACE['trace_id'] = kwargs.get('trace_id') or str(uuid.uuid4())\n",
    "    if 'eval_quality' == 'cost_meter':\n",
    "        _COST['tokens_in'] += int(kwargs.get('tokens_in',0))\n",
    "        _COST['tokens_out']+= int(kwargs.get('tokens_out',0))\n",
    "        _COST['cost']      += float(kwargs.get('cost',0.0))\n",
    "        evt.update(_COST)\n",
    "    _TRACE['events'].append(evt)\n",
    "    return {'ok': True, 'trace_id': _TRACE['trace_id'], 'event': evt}\n",
    "\n",
    "\n",
    "TOOLS = {\n",
    "\n",
    "    'tool_trace_start': tool_trace_start,\n",
    "\n",
    "    'tool_trace_log': tool_trace_log,\n",
    "\n",
    "    'tool_trace_end': tool_trace_end,\n",
    "\n",
    "    'tool_apim_set_correlation': tool_apim_set_correlation,\n",
    "\n",
    "    'tool_sk_plan_record': tool_sk_plan_record,\n",
    "\n",
    "    'tool_lg_node_event': tool_lg_node_event,\n",
    "\n",
    "    'tool_rag_query': tool_rag_query,\n",
    "\n",
    "    'tool_http_request': tool_http_request,\n",
    "\n",
    "    'tool_soap_action': tool_soap_action,\n",
    "\n",
    "    'tool_calc_eval': tool_calc_eval,\n",
    "\n",
    "    'tool_cost_meter': tool_cost_meter,\n",
    "\n",
    "    'tool_eval_quality': tool_eval_quality,\n",
    "\n",
    "}\n",
    "print('Tools:', list(TOOLS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ef721",
   "metadata": {
    "tags": [
     "AGENTS"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [AGENTS]\n",
    "\n",
    "class Agent_channel_agent:\n",
    "\"\n",
    "        \"    def __init__(self, kernel):\n",
    "\"\n",
    "        \"        self.kernel = kernel\n",
    "\"\n",
    "        \"        self.name = \"Channel Agent (PVA)\"\n",
    "\"\n",
    "        \"        self.system_message = \"Channel entry \\u2014 attaches trace_id/span_id and forwards.\"\n",
    "\"\n",
    "        \"        self.skills = [\"tool_trace_start\", \"tool_trace_log\", \"tool_trace_end\"]\n",
    "\"\n",
    "        \"    async def run(self, user_text: str) -> str:\n",
    "\"\n",
    "        \"        try:\n",
    "\"\n",
    "        \"            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "\"\n",
    "        \"            return str(result)\n",
    "\"\n",
    "        \"        except Exception as e:\n",
    "\"\n",
    "        \"            return f\"[Channel Agent (PVA) stub] Adjust SK call. Error: {e}\"\n",
    "\"\n",
    "        \"    def available_tools(self):\n",
    "\"\n",
    "        \"        return [t for t in self.skills if t in TOOLS]\n",
    "\"\n",
    "        \"    def call(self, tool_name: str, **kwargs):\n",
    "\"\n",
    "        \"        fn = TOOLS.get(tool_name)\n",
    "\"\n",
    "        \"        if not fn:\n",
    "\"\n",
    "        \"            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "\"\n",
    "        \"        return fn(**kwargs)\n",
    "\"\n",
    "\n",
    "class Agent_gateway_agent:\n",
    "\"\n",
    "        \"    def __init__(self, kernel):\n",
    "\"\n",
    "        \"        self.kernel = kernel\n",
    "\"\n",
    "        \"        self.name = \"Gateway Agent (APIM)\"\n",
    "\"\n",
    "        \"        self.system_message = \"API Management correlation policies inbound/outbound.\"\n",
    "\"\n",
    "        \"        self.skills = [\"tool_apim_set_correlation\", \"tool_trace_log\"]\n",
    "\"\n",
    "        \"    async def run(self, user_text: str) -> str:\n",
    "\"\n",
    "        \"        try:\n",
    "\"\n",
    "        \"            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "\"\n",
    "        \"            return str(result)\n",
    "\"\n",
    "        \"        except Exception as e:\n",
    "\"\n",
    "        \"            return f\"[Gateway Agent (APIM) stub] Adjust SK call. Error: {e}\"\n",
    "\"\n",
    "        \"    def available_tools(self):\n",
    "\"\n",
    "        \"        return [t for t in self.skills if t in TOOLS]\n",
    "\"\n",
    "        \"    def call(self, tool_name: str, **kwargs):\n",
    "\"\n",
    "        \"        fn = TOOLS.get(tool_name)\n",
    "\"\n",
    "        \"        if not fn:\n",
    "\"\n",
    "        \"            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "\"\n",
    "        \"        return fn(**kwargs)\n",
    "\"\n",
    "\n",
    "class Agent_sk_agent:\n",
    "\"\n",
    "        \"    def __init__(self, kernel):\n",
    "\"\n",
    "        \"        self.kernel = kernel\n",
    "\"\n",
    "        \"        self.name = \"SK Planner\"\n",
    "\"\n",
    "        \"        self.system_message = \"Semantic Kernel planner \\u2014 records chosen tools and retries.\"\n",
    "\"\n",
    "        \"        self.skills = [\"tool_sk_plan_record\", \"tool_cost_meter\", \"tool_trace_log\"]\n",
    "\"\n",
    "        \"    async def run(self, user_text: str) -> str:\n",
    "\"\n",
    "        \"        try:\n",
    "\"\n",
    "        \"            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "\"\n",
    "        \"            return str(result)\n",
    "\"\n",
    "        \"        except Exception as e:\n",
    "\"\n",
    "        \"            return f\"[SK Planner stub] Adjust SK call. Error: {e}\"\n",
    "\"\n",
    "        \"    def available_tools(self):\n",
    "\"\n",
    "        \"        return [t for t in self.skills if t in TOOLS]\n",
    "\"\n",
    "        \"    def call(self, tool_name: str, **kwargs):\n",
    "\"\n",
    "        \"        fn = TOOLS.get(tool_name)\n",
    "\"\n",
    "        \"        if not fn:\n",
    "\"\n",
    "        \"            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "\"\n",
    "        \"        return fn(**kwargs)\n",
    "\"\n",
    "\n",
    "class Agent_lg_agent:\n",
    "\"\n",
    "        \"    def __init__(self, kernel):\n",
    "\"\n",
    "        \"        self.kernel = kernel\n",
    "\"\n",
    "        \"        self.name = \"LangGraph Node Runner\"\n",
    "\"\n",
    "        \"        self.system_message = \"Runs nodes and emits node events.\"\n",
    "\"\n",
    "        \"        self.skills = [\"tool_lg_node_event\", \"tool_trace_log\"]\n",
    "\"\n",
    "        \"    async def run(self, user_text: str) -> str:\n",
    "\"\n",
    "        \"        try:\n",
    "\"\n",
    "        \"            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "\"\n",
    "        \"            return str(result)\n",
    "\"\n",
    "        \"        except Exception as e:\n",
    "\"\n",
    "        \"            return f\"[LangGraph Node Runner stub] Adjust SK call. Error: {e}\"\n",
    "\"\n",
    "        \"    def available_tools(self):\n",
    "\"\n",
    "        \"        return [t for t in self.skills if t in TOOLS]\n",
    "\"\n",
    "        \"    def call(self, tool_name: str, **kwargs):\n",
    "\"\n",
    "        \"        fn = TOOLS.get(tool_name)\n",
    "\"\n",
    "        \"        if not fn:\n",
    "\"\n",
    "        \"            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "\"\n",
    "        \"        return fn(**kwargs)\n",
    "\"\n",
    "\n",
    "class Agent_tools_agent:\n",
    "\"\n",
    "        \"    def __init__(self, kernel):\n",
    "\"\n",
    "        \"        self.kernel = kernel\n",
    "\"\n",
    "        \"        self.name = \"Tools Agent\"\n",
    "\"\n",
    "        \"        self.system_message = \"Executes RAG/HTTP/SOAP/CALC with telemetry.\"\n",
    "\"\n",
    "        \"        self.skills = [\"tool_rag_query\", \"tool_http_request\", \"tool_soap_action\", \"tool_calc_eval\", \"tool_trace_log\"]\n",
    "\"\n",
    "        \"    async def run(self, user_text: str) -> str:\n",
    "\"\n",
    "        \"        try:\n",
    "\"\n",
    "        \"            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "\"\n",
    "        \"            return str(result)\n",
    "\"\n",
    "        \"        except Exception as e:\n",
    "\"\n",
    "        \"            return f\"[Tools Agent stub] Adjust SK call. Error: {e}\"\n",
    "\"\n",
    "        \"    def available_tools(self):\n",
    "\"\n",
    "        \"        return [t for t in self.skills if t in TOOLS]\n",
    "\"\n",
    "        \"    def call(self, tool_name: str, **kwargs):\n",
    "\"\n",
    "        \"        fn = TOOLS.get(tool_name)\n",
    "\"\n",
    "        \"        if not fn:\n",
    "\"\n",
    "        \"            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "\"\n",
    "        \"        return fn(**kwargs)\n",
    "\"\n",
    "\n",
    "class Agent_obs_agent:\n",
    "\"\n",
    "        \"    def __init__(self, kernel):\n",
    "\"\n",
    "        \"        self.kernel = kernel\n",
    "\"\n",
    "        \"        self.name = \"Observability Agent\"\n",
    "\"\n",
    "        \"        self.system_message = \"Sends OTLP to Insights/Logs and performs eval.\"\n",
    "\"\n",
    "        \"        self.skills = [\"tool_eval_quality\", \"tool_trace_log\", \"tool_trace_end\"]\n",
    "\"\n",
    "        \"    async def run(self, user_text: str) -> str:\n",
    "\"\n",
    "        \"        try:\n",
    "\"\n",
    "        \"            result = await self.kernel.invoke_prompt(self.system_message + \"\\n\\nUser: \" + user_text)\n",
    "\"\n",
    "        \"            return str(result)\n",
    "\"\n",
    "        \"        except Exception as e:\n",
    "\"\n",
    "        \"            return f\"[Observability Agent stub] Adjust SK call. Error: {e}\"\n",
    "\"\n",
    "        \"    def available_tools(self):\n",
    "\"\n",
    "        \"        return [t for t in self.skills if t in TOOLS]\n",
    "\"\n",
    "        \"    def call(self, tool_name: str, **kwargs):\n",
    "\"\n",
    "        \"        fn = TOOLS.get(tool_name)\n",
    "\"\n",
    "        \"        if not fn:\n",
    "\"\n",
    "        \"            raise ValueError(f\"Tool not found: {tool_name}\")\n",
    "\"\n",
    "        \"        return fn(**kwargs)\n",
    "\"\n",
    "\n",
    "\n",
    "# Instances\n",
    "\n",
    "agent_channel_agent = Agent_channel_agent(kernel)\n",
    "\n",
    "agent_gateway_agent = Agent_gateway_agent(kernel)\n",
    "\n",
    "agent_sk_agent = Agent_sk_agent(kernel)\n",
    "\n",
    "agent_lg_agent = Agent_lg_agent(kernel)\n",
    "\n",
    "agent_tools_agent = Agent_tools_agent(kernel)\n",
    "\n",
    "agent_obs_agent = Agent_obs_agent(kernel)\n",
    "\n",
    "print('Agents:', ['agent_channel_agent', 'agent_gateway_agent', 'agent_sk_agent', 'agent_lg_agent', 'agent_tools_agent', 'agent_obs_agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7604e6",
   "metadata": {
    "tags": [
     "WIRES"
    ]
   },
   "outputs": [],
   "source": [
    "# %% [WIRES]\n",
    "WIRES = {\n",
    "  \"Channel Agent (PVA)\": {\n",
    "    \"tools\": [\n",
    "      \"tool_trace_start\",\n",
    "      \"tool_trace_log\",\n",
    "      \"tool_trace_end\"\n",
    "    ]\n",
    "  },\n",
    "  \"Gateway Agent (APIM)\": {\n",
    "    \"tools\": [\n",
    "      \"tool_apim_set_correlation\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"SK Planner\": {\n",
    "    \"tools\": [\n",
    "      \"tool_sk_plan_record\",\n",
    "      \"tool_cost_meter\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"LangGraph Node Runner\": {\n",
    "    \"tools\": [\n",
    "      \"tool_lg_node_event\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Tools Agent\": {\n",
    "    \"tools\": [\n",
    "      \"tool_rag_query\",\n",
    "      \"tool_http_request\",\n",
    "      \"tool_soap_action\",\n",
    "      \"tool_calc_eval\",\n",
    "      \"tool_trace_log\"\n",
    "    ]\n",
    "  },\n",
    "  \"Observability Agent\": {\n",
    "    \"tools\": [\n",
    "      \"tool_eval_quality\",\n",
    "      \"tool_trace_log\",\n",
    "      \"tool_trace_end\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "print('Wiring entries:', len(WIRES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc401b4",
   "metadata": {
    "tags": [
     "DEMO"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# %% [DEMO]\n",
    "import os, getpass, types, asyncio, uuid, time, json as _json\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "os.environ.setdefault(\"AZURE_OPENAI_ENDPOINT\",    \"https://4th-openai-resource.openai.azure.com\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_DEPLOYMENT\",  \"gpt-35-turbo\")\n",
    "os.environ.setdefault(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\")\n",
    "if not os.getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter AZURE_OPENAI_API_KEY (hidden): \").strip()\n",
    "try:\n",
    "    kernel\n",
    "except NameError:\n",
    "    kernel = Kernel()\n",
    "try:\n",
    "    kernel.remove_service(\"azure\")\n",
    "except Exception:\n",
    "    pass\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=\"azure\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "))\n",
    "async def _run_with_azure(self, user_text: str):\n",
    "    prompt = (getattr(self, \"system_message\", \"\") or \"\") + \"\\\\n\\\\nUser: \" + str(user_text)\n",
    "    result = await self.kernel.invoke_prompt(prompt, service_id=\"azure\")\n",
    "    return str(result)\n",
    "patched = []\n",
    "for name, obj in list(globals().items()):\n",
    "    if name.startswith(\"agent_\"):\n",
    "        try:\n",
    "            obj.kernel = kernel\n",
    "            obj.run = types.MethodType(_run_with_azure, obj)\n",
    "            patched.append(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "print(\"Patched run() for:\", patched if patched else \"(none)\")\n",
    "async def demo():\n",
    "    trace_id = str(uuid.uuid4())\n",
    "    ch = globals().get(\"agent_channel_agent\")\n",
    "    gw = globals().get(\"agent_gateway_agent\")\n",
    "    sk = globals().get(\"agent_sk_agent\")\n",
    "    lg = globals().get(\"agent_lg_agent\")\n",
    "    tl = globals().get(\"agent_tools_agent\")\n",
    "    ob = globals().get(\"agent_obs_agent\")\n",
    "    if ch:\n",
    "        print(ch.call(\"tool_trace_start\", trace_id=trace_id, span_id=str(uuid.uuid4()), user_id=\"user-123\", channel=\"pva\"))\n",
    "        print(await ch.run(\"User asks: explain trace propagation.\"))\n",
    "    if gw:\n",
    "        print(gw.call(\"tool_apim_set_correlation\", in_headers={\"traceparent\": trace_id}, out_headers={\"traceparent\": trace_id}))\n",
    "        gw.call(\"tool_trace_log\", stage=\"apim.forward\")\n",
    "    if sk:\n",
    "        print(await sk.run(\"Plan tools and enforce correlation headers.\"))\n",
    "        sk.call(\"tool_sk_plan_record\", tools=[\"rag\",\"http\",\"calc\"], retries=0)\n",
    "        sk.call(\"tool_cost_meter\", tokens_in=100, tokens_out=20, cost=0.0020)\n",
    "    if lg:\n",
    "        print(await lg.run(\"Run nodes with trace propagation to tools.\"))\n",
    "        lg.call(\"tool_lg_node_event\", node=\"retrieve\", state=\"start\")\n",
    "        lg.call(\"tool_lg_node_event\", node=\"analyze\", state=\"start\")\n",
    "    if tl:\n",
    "        tl.call(\"tool_rag_query\", k=5, latency_ms=45, index=\"docs\")\n",
    "        tl.call(\"tool_http_request\", method=\"GET\", url=\"https://example/api\", status=200, latency_ms=120, body_size=1024)\n",
    "        tl.call(\"tool_calc_eval\", expr=\"(3*7)+2\", latency_ms=2)\n",
    "    if ob:\n",
    "        ob.call(\"tool_eval_quality\", quality=\"good\", safety=\"ok\")\n",
    "        end = ob.call(\"tool_trace_end\", finalize=True)\n",
    "        print(\"Trace summary:\", _json.dumps(end, indent=2))\n",
    "    print(\"LLM demo:\")\n",
    "    if sk:\n",
    "        try:\n",
    "            out = await sk.run(\"Why is carrying a trace_id across PVA → APIM → SK → Tools important? Answer concisely.\")\n",
    "            print(out)\n",
    "        except Exception as e:\n",
    "            print(\"[demo] invoke failed:\", e)\n",
    "await demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
