study:
  id: AML.CS0005
  name: Attack on Machine Translation Services
  object-type: case-study
  summary: >-
    Machine translation services (such as Google Translate, Bing Translator, and
    Systran Translate) provide public-facing UIs and APIs.

    A research group at UC Berkeley utilized these public endpoints to create a
    replicated model with near-production state-of-the-art translation quality.

    Beyond demonstrating that IP can be functionally stolen from a black-box
    system, they used the replicated model to successfully transfer adversarial
    examples to the real production services.

    These adversarial inputs successfully cause targeted word flips, vulgar
    outputs, and dropped sentences on Google Translate and Systran Translate
    websites.
  incident-date: '2020-04-30'
  incident-date-granularity: DATE
  procedure:
  - tactic: AML.TA0002
    technique: AML.T0000
    description: >-
      The researchers used published research papers to identify the datasets
      and model architectures used by the target translation services.
  - tactic: AML.TA0003
    technique: AML.T0002.000
    description: >-
      The researchers gathered similar datasets that the target translation
      services used.
  - tactic: AML.TA0003
    technique: AML.T0002.001
    description: >-
      The researchers gathered similar model architectures that the target
      translation services used.
  - tactic: AML.TA0000
    technique: AML.T0040
    description: >-
      They abused a public facing application to query the model and produced
      machine translated sentence pairs as training data.
  - tactic: AML.TA0001
    technique: AML.T0005.001
    description: >-
      Using these translated sentence pairs, the researchers trained a model
      that replicates the behavior of the target model.
  - tactic: AML.TA0011
    technique: AML.T0048.004
    description: >-
      By replicating the model with high fidelity, the researchers
      demonstrated that an adversary could steal a model and violate the
      victim's intellectual property rights.
  - tactic: AML.TA0001
    technique: AML.T0043.002
    description: >-
      The replicated models were used to generate adversarial examples that
      successfully transferred to the black-box translation services.
  - tactic: AML.TA0011
    technique: AML.T0015
    description: >-
      The adversarial examples were used to evade the machine translation
      services by a variety of means. This included targeted word flips,
      vulgar outputs, and dropped sentences.
  - tactic: AML.TA0011
    technique: AML.T0031
    description: >-
      Adversarial attacks can cause errors that cause reputational damage to
      the company of the translation service and decrease user trust in
      AI-powered services.
  target: Google Translate, Bing Translator, Systran Translate
  actor: Berkeley Artificial Intelligence Research
  case-study-type: exercise
  references:
  - title: >-
      Wallace, Eric, et al. "Imitation Attacks and Defenses for Black-box
      Machine Translation Systems" EMNLP 2020
    url: https://arxiv.org/abs/2004.15015
  - title: >-
      Project Page, "Imitation Attacks and Defenses for Black-box Machine
      Translation Systems"
    url: https://www.ericswallace.com/imitation
  - title: Google under fire for mistranslating Chinese amid Hong Kong protests
    url: >-
      https://thehill.com/policy/international/asia-pacific/449164-google-under-fire-for-mistranslating-chinese-amid-hong-kong/
anchors: {}
